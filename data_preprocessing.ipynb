{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99408bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute as needed\n",
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5e8296",
   "metadata": {},
   "source": [
    "## Process Books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53aca0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_BOOKS_FOLDER_PATH = \"raw_data/books/\"\n",
    "PROCESSED_BOOKS_FOLDER_PATH = \"processed_data/books/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4284d530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing .DS_Store\n",
      "Skipping .DS_Store as it is not a valid file.\n",
      "Processing Sunrise on the Reaping.pdf\n",
      "Skipping Sunrise on the Reaping.pdf as it has already been processed.\n",
      "Processing All Fours (Miranda July).pdf\n",
      "Skipping All Fours (Miranda July).pdf as it has already been processed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import PyPDF2\n",
    "from modules.embedding_tracking import add_new_file, file_exists\n",
    "\n",
    "available_files = os.listdir(RAW_BOOKS_FOLDER_PATH)\n",
    "\n",
    "for i in available_files:\n",
    "    print(f\"Processing {i}\")\n",
    "    \n",
    "    processed_fname = \".\".join(i.split(\".\")[:-1])+\".txt\"\n",
    "    \n",
    "    if file_exists(processed_fname):\n",
    "        print(f\"Skipping {i} as it has already been processed.\")\n",
    "        continue\n",
    "    \n",
    "    text = \"\"\n",
    "    if i.endswith(\".pdf\"):\n",
    "        fname = os.path.join(RAW_BOOKS_FOLDER_PATH, i)\n",
    "        reader = PyPDF2.PdfReader(fname)\n",
    "        for page_num in range(len(reader.pages)):\n",
    "            page = reader.pages[page_num]\n",
    "            text += page.extract_text()\n",
    "            \n",
    "    else:\n",
    "        # invalid file types\n",
    "        print(f\"Skipping {i} as it is not a valid file.\")\n",
    "        continue\n",
    "    \n",
    "    with open(os.path.join(PROCESSED_BOOKS_FOLDER_PATH, processed_fname), \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(text)\n",
    "        add_new_file(processed_fname)\n",
    "        \n",
    "    print(f\"Finished processing {i}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e3deab",
   "metadata": {},
   "source": [
    "### Store to storage as vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c92ca5",
   "metadata": {},
   "source": [
    "#### BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72b25dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yudhistiraonggowarsito/Documents/SMU/Courses/CS614 - Generative AI with Large Language Models/Project/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import transformers\n",
    "\n",
    "model_name = \"bert-base-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "bert_model = transformers.BertModel.from_pretrained(model_name)\n",
    "bert_embedding_layer = bert_model.embeddings\n",
    "bert_word_embeddings = bert_embedding_layer.word_embeddings\n",
    "\n",
    "def generate_bert_embeddings(text, truncate=False):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=truncate, padding=True, add_special_tokens=True, max_length=512)\n",
    "    outputs = bert_model(**inputs)\n",
    "    return outputs.last_hidden_state.squeeze().detach().numpy().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b0967e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing All Fours (Miranda July).txt\n",
      "Tokenizing chunk 1 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 2 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 3 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 4 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 5 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 6 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 7 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 8 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 9 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 10 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 11 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 12 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 13 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 14 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 15 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 16 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 17 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 18 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 19 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 20 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 21 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 22 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 23 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 24 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 25 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 26 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 27 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 28 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 29 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 30 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 31 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 32 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 33 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 34 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 35 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 36 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 37 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 38 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 39 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 40 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 41 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 42 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 43 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 44 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 45 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 46 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 47 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 48 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 49 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 50 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 51 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 52 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 53 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 54 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 55 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 56 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 57 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 58 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 59 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 60 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 61 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 62 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 63 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 64 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 65 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 66 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 67 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 68 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 69 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 70 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 71 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 72 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 73 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 74 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 75 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 76 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 77 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 78 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 79 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 80 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 81 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 82 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 83 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 84 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 85 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 86 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 87 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 88 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 89 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 90 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 91 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 92 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 93 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 94 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 95 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 96 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 97 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 98 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 99 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 100 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 101 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 102 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 103 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 104 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 105 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 106 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 107 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 108 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 109 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 110 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 111 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 112 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 113 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 114 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 115 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 116 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 117 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 118 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 119 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 120 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 121 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 122 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 123 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 124 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 125 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 126 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 127 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 128 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 129 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 130 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 131 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 132 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 133 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 134 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 135 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 136 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 137 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 138 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 139 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 140 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 141 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 142 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 143 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 144 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 145 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 146 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 147 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 148 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 149 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 150 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 151 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 152 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 153 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 154 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 155 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 156 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 157 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 158 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 159 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 160 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 161 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 162 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 163 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 164 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 165 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 166 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 167 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 168 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 169 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 170 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 171 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 172 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 173 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 174 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 175 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 176 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 177 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 178 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 179 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 180 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 181 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 182 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 183 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 184 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 185 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 186 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 187 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 188 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 189 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 190 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 191 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 192 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 193 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 194 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 195 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 196 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 197 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 198 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 199 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 200 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 201 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 202 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 203 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 204 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 205 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 206 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 207 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 208 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 209 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 210 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 211 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 212 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 213 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 214 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 215 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 216 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 217 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 218 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 219 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 220 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 221 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 222 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 223 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 224 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 225 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 226 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 227 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 228 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 229 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 230 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 231 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 232 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 233 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 234 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 235 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 236 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 237 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 238 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 239 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 240 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 241 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 242 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 243 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 244 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 245 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 246 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 247 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 248 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 249 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 250 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 251 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 252 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 253 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 254 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 255 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 256 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 257 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 258 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 259 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 260 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 261 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 262 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 263 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 264 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 265 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 266 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 267 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 268 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 269 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 270 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 271 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 272 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 273 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 274 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 275 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 276 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 277 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 278 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 279 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 280 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 281 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 282 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 283 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 284 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 285 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 286 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 287 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 288 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 289 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 290 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 291 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 292 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 293 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 294 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 295 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 296 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 297 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 298 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 299 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 300 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 301 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 302 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 303 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 304 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 305 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 306 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 307 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 308 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 309 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 310 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 311 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 312 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 313 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 314 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 315 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 316 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 317 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 318 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 319 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 320 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 321 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 322 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 323 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 324 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 325 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 326 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 327 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 328 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 329 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 330 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 331 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 332 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 333 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 334 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 335 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 336 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 337 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 338 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 339 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 340 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 341 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 342 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 343 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 344 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 345 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 346 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 347 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 348 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 349 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 350 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 351 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 352 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 353 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 354 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 355 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 356 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 357 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 358 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 359 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 360 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 361 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 362 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 363 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 364 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 365 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 366 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 367 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 368 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 369 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 370 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 371 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 372 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 373 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 374 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 375 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 376 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 377 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 378 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 379 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 380 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 381 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 382 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 383 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 384 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 385 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 386 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 387 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 388 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 389 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 390 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 391 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 392 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 393 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 394 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 395 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 396 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 397 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 398 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 399 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 400 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 401 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 402 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 403 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 404 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 405 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 406 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 407 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 408 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 409 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 410 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 411 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 412 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 413 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 414 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 415 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 416 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 417 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 418 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 419 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 420 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 421 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 422 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 423 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 424 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 425 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 426 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 427 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 428 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 429 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 430 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 431 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 432 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 433 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 434 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 435 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 436 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 437 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 438 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 439 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 440 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 441 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 442 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 443 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 444 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 445 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 446 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 447 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 448 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 449 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 450 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 451 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 452 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 453 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 454 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 455 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 456 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 457 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 458 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 459 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 460 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 461 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 462 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 463 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 464 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 465 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 466 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 467 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 468 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 469 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 470 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 471 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 472 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 473 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 474 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 475 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 476 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 477 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 478 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 479 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 480 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 481 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 482 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 483 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 484 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 485 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 486 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 487 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 488 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 489 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 490 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 491 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 492 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 493 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 494 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 495 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 496 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 497 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 498 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 499 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 500 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 501 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 502 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 503 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 504 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 505 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 506 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 507 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 508 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 509 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 510 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 511 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 512 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 513 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 514 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 515 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 516 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 517 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 518 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 519 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 520 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 521 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 522 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 523 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 524 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 525 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 526 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 527 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 528 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 529 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 530 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 531 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 532 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 533 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 534 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 535 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 536 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 537 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 538 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 539 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 540 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 541 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 542 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 543 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 544 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 545 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 546 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 547 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 548 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 549 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 550 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 551 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 552 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 553 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 554 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 555 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 556 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 557 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 558 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 559 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 560 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 561 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 562 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 563 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 564 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 565 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 566 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 567 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 568 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 569 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 570 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 571 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 572 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 573 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 574 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 575 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 576 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 577 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 578 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 579 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 580 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 581 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 582 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 583 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 584 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 585 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 586 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 587 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 588 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 589 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 590 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 591 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 592 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 593 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 594 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 595 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 596 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 597 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 598 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 599 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 600 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 601 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 602 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 603 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 604 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 605 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 606 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 607 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 608 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 609 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 610 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 611 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 612 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 613 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 614 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 615 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 616 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 617 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 618 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 619 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 620 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 621 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 622 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 623 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 624 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 625 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 626 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 627 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 628 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 629 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 630 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 631 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 632 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 633 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 634 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 635 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 636 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 637 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 638 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 639 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 640 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 641 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 642 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 643 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 644 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 645 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 646 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 647 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 648 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 649 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 650 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 651 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 652 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 653 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 654 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 655 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 656 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 657 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 658 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 659 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 660 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 661 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 662 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 663 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 664 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 665 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 666 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 667 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 668 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 669 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 670 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 671 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 672 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 673 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 674 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 675 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 676 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 677 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 678 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 679 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 680 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 681 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 682 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 683 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 684 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 685 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 686 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 687 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 688 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 689 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 690 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 691 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 692 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 693 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 694 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 695 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 696 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 697 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 698 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 699 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 700 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 701 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 702 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 703 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 704 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 705 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 706 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 707 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 708 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 709 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 710 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 711 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 712 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 713 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 714 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 715 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 716 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 717 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 718 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 719 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 720 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 721 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 722 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 723 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 724 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 725 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 726 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 727 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 728 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 729 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 730 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 731 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 732 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 733 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 734 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 735 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 736 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 737 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 738 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 739 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 740 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 741 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 742 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 743 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 744 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 745 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 746 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 747 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 748 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 749 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 750 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 751 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 752 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 753 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 754 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 755 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 756 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 757 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 758 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 759 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 760 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 761 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 762 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 763 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 764 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 765 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 766 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 767 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 768 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 769 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 770 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 771 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 772 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 773 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 774 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 775 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 776 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 777 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 778 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 779 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 780 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 781 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 782 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 783 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 784 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 785 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 786 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 787 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 788 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 789 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 790 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 791 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 792 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 793 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 794 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 795 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 796 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 797 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 798 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 799 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 800 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 801 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 802 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 803 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 804 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 805 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 806 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 807 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 808 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 809 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 810 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 811 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 812 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 813 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 814 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 815 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 816 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 817 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 818 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 819 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 820 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 821 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 822 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 823 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 824 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 825 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 826 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 827 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 828 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 829 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 830 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 831 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 832 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 833 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 834 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 835 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 836 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 837 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 838 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 839 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 840 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 841 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 842 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 843 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 844 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 845 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 846 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 847 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 848 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 849 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 850 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 851 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 852 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 853 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 854 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 855 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 856 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 857 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 858 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 859 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 860 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 861 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 862 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 863 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 864 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 865 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 866 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 867 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 868 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 869 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 870 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 871 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 872 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 873 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 874 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 875 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 876 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 877 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 878 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 879 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 880 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 881 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 882 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 883 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 884 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 885 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 886 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 887 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 888 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 889 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 890 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 891 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 892 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 893 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 894 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 895 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 896 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 897 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 898 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 899 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 900 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 901 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 902 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 903 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 904 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 905 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 906 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 907 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 908 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 909 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 910 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 911 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 912 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 913 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 914 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 915 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 916 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 917 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 918 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 919 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 920 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 921 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 922 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 923 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 924 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 925 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 926 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 927 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 928 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 929 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 930 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 931 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 932 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 933 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 934 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 935 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 936 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 937 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 938 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 939 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 940 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 941 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 942 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 943 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 944 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 945 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 946 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 947 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 948 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 949 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 950 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 951 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 952 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 953 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 954 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 955 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 956 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 957 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 958 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 959 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 960 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 961 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 962 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 963 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 964 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 965 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 966 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 967 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 968 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 969 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 970 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 971 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 972 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 973 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 974 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 975 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 976 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 977 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 978 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 979 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 980 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 981 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 982 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 983 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 984 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 985 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 986 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 987 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 988 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 989 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 990 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 991 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 992 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 993 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 994 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 995 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 996 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 997 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 998 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 999 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 1000 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 1001 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 1002 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 1003 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 1004 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 1005 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 1006 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 1007 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 1008 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 1009 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 1010 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 1011 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 1012 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 1013 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 1014 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 1015 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 1016 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 1017 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 1018 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 1019 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 1020 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 1021 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 1022 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 1023 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 1024 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 1025 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 1026 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 1027 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 1028 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 1029 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 1030 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 1031 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 1032 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 1033 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 1034 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 1035 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 1036 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 1037 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 1038 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 1039 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 1040 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 1041 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 1042 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 1043 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 1044 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 1045 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 1046 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 1047 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 1048 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 1049 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 1050 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 1051 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 1052 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 1053 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 1054 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 1055 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 1056 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 1057 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 1058 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 1059 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 1060 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 1061 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 1062 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 1063 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 1064 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 1065 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 1066 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 1067 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 1068 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 1069 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 1070 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 1071 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 1072 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 1073 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 1074 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 1075 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 1076 of All Fours (Miranda July).txt\n",
      "Tokenizing chunk 1077 of All Fours (Miranda July).txt\n",
      "Finished processing All Fours (Miranda July).txt for embeddings.\n",
      "Tokenizing Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 2 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 3 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 4 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 5 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 6 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 7 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 8 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 9 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 10 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 11 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 12 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 13 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 14 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 15 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 16 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 17 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 18 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 19 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 20 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 21 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 22 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 23 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 24 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 25 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 26 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 27 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 28 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 29 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 30 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 31 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 32 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 33 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 34 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 35 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 36 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 37 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 38 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 39 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 40 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 41 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 42 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 43 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 44 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 45 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 46 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 47 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 48 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 49 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 50 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 51 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 52 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 53 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 54 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 55 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 56 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 57 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 58 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 59 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 60 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 61 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 62 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 63 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 64 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 65 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 66 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 67 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 68 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 69 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 70 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 71 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 72 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 73 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 74 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 75 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 76 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 77 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 78 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 79 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 80 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 81 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 82 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 83 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 84 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 85 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 86 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 87 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 88 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 89 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 90 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 91 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 92 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 93 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 94 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 95 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 96 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 97 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 98 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 99 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 100 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 101 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 102 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 103 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 104 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 105 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 106 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 107 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 108 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 109 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 110 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 111 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 112 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 113 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 114 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 115 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 116 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 117 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 118 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 119 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 120 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 121 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 122 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 123 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 124 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 125 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 126 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 127 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 128 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 129 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 130 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 131 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 132 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 133 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 134 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 135 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 136 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 137 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 138 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 139 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 140 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 141 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 142 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 143 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 144 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 145 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 146 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 147 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 148 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 149 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 150 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 151 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 152 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 153 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 154 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 155 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 156 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 157 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 158 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 159 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 160 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 161 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 162 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 163 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 164 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 165 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 166 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 167 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 168 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 169 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 170 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 171 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 172 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 173 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 174 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 175 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 176 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 177 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 178 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 179 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 180 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 181 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 182 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 183 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 184 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 185 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 186 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 187 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 188 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 189 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 190 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 191 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 192 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 193 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 194 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 195 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 196 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 197 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 198 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 199 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 200 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 201 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 202 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 203 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 204 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 205 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 206 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 207 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 208 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 209 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 210 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 211 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 212 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 213 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 214 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 215 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 216 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 217 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 218 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 219 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 220 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 221 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 222 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 223 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 224 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 225 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 226 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 227 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 228 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 229 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 230 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 231 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 232 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 233 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 234 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 235 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 236 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 237 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 238 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 239 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 240 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 241 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 242 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 243 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 244 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 245 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 246 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 247 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 248 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 249 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 250 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 251 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 252 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 253 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 254 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 255 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 256 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 257 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 258 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 259 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 260 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 261 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 262 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 263 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 264 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 265 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 266 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 267 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 268 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 269 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 270 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 271 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 272 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 273 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 274 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 275 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 276 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 277 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 278 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 279 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 280 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 281 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 282 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 283 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 284 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 285 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 286 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 287 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 288 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 289 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 290 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 291 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 292 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 293 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 294 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 295 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 296 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 297 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 298 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 299 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 300 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 301 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 302 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 303 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 304 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 305 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 306 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 307 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 308 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 309 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 310 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 311 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 312 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 313 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 314 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 315 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 316 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 317 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 318 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 319 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 320 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 321 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 322 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 323 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 324 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 325 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 326 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 327 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 328 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 329 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 330 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 331 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 332 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 333 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 334 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 335 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 336 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 337 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 338 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 339 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 340 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 341 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 342 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 343 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 344 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 345 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 346 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 347 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 348 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 349 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 350 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 351 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 352 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 353 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 354 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 355 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 356 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 357 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 358 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 359 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 360 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 361 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 362 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 363 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 364 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 365 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 366 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 367 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 368 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 369 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 370 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 371 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 372 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 373 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 374 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 375 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 376 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 377 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 378 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 379 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 380 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 381 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 382 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 383 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 384 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 385 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 386 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 387 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 388 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 389 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 390 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 391 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 392 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 393 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 394 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 395 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 396 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 397 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 398 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 399 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 400 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 401 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 402 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 403 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 404 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 405 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 406 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 407 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 408 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 409 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 410 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 411 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 412 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 413 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 414 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 415 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 416 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 417 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 418 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 419 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 420 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 421 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 422 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 423 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 424 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 425 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 426 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 427 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 428 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 429 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 430 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 431 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 432 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 433 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 434 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 435 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 436 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 437 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 438 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 439 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 440 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 441 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 442 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 443 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 444 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 445 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 446 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 447 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 448 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 449 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 450 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 451 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 452 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 453 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 454 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 455 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 456 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 457 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 458 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 459 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 460 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 461 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 462 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 463 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 464 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 465 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 466 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 467 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 468 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 469 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 470 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 471 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 472 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 473 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 474 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 475 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 476 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 477 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 478 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 479 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 480 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 481 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 482 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 483 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 484 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 485 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 486 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 487 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 488 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 489 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 490 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 491 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 492 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 493 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 494 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 495 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 496 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 497 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 498 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 499 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 500 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 501 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 502 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 503 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 504 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 505 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 506 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 507 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 508 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 509 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 510 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 511 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 512 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 513 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 514 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 515 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 516 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 517 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 518 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 519 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 520 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 521 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 522 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 523 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 524 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 525 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 526 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 527 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 528 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 529 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 530 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 531 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 532 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 533 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 534 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 535 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 536 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 537 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 538 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 539 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 540 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 541 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 542 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 543 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 544 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 545 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 546 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 547 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 548 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 549 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 550 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 551 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 552 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 553 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 554 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 555 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 556 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 557 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 558 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 559 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 560 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 561 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 562 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 563 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 564 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 565 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 566 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 567 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 568 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 569 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 570 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 571 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 572 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 573 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 574 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 575 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 576 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 577 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 578 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 579 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 580 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 581 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 582 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 583 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 584 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 585 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 586 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 587 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 588 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 589 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 590 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 591 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 592 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 593 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 594 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 595 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 596 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 597 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 598 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 599 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 600 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 601 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 602 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 603 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 604 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 605 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 606 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 607 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 608 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 609 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 610 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 611 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 612 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 613 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 614 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 615 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 616 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 617 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 618 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 619 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 620 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 621 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 622 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 623 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 624 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 625 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 626 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 627 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 628 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 629 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 630 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 631 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 632 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 633 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 634 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 635 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 636 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 637 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 638 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 639 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 640 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 641 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 642 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 643 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 644 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 645 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 646 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 647 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 648 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 649 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 650 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 651 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 652 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 653 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 654 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 655 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 656 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 657 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 658 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 659 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 660 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 661 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 662 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 663 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 664 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 665 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 666 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 667 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 668 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 669 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 670 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 671 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 672 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 673 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 674 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 675 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 676 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 677 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 678 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 679 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 680 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 681 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 682 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 683 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 684 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 685 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 686 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 687 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 688 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 689 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 690 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 691 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 692 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 693 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 694 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 695 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 696 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 697 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 698 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 699 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 700 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 701 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 702 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 703 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 704 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 705 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 706 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 707 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 708 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 709 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 710 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 711 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 712 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 713 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 714 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 715 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 716 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 717 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 718 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 719 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 720 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 721 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 722 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 723 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 724 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 725 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 726 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 727 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 728 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 729 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 730 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 731 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 732 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 733 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 734 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 735 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 736 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 737 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 738 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 739 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 740 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 741 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 742 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 743 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 744 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 745 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 746 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 747 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 748 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 749 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 750 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 751 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 752 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 753 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 754 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 755 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 756 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 757 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 758 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 759 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 760 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 761 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 762 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 763 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 764 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 765 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 766 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 767 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 768 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 769 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 770 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 771 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 772 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 773 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 774 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 775 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 776 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 777 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 778 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 779 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 780 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 781 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 782 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 783 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 784 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 785 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 786 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 787 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 788 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 789 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 790 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 791 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 792 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 793 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 794 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 795 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 796 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 797 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 798 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 799 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 800 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 801 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 802 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 803 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 804 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 805 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 806 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 807 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 808 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 809 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 810 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 811 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 812 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 813 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 814 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 815 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 816 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 817 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 818 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 819 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 820 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 821 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 822 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 823 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 824 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 825 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 826 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 827 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 828 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 829 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 830 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 831 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 832 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 833 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 834 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 835 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 836 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 837 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 838 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 839 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 840 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 841 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 842 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 843 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 844 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 845 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 846 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 847 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 848 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 849 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 850 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 851 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 852 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 853 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 854 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 855 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 856 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 857 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 858 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 859 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 860 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 861 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 862 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 863 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 864 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 865 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 866 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 867 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 868 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 869 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 870 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 871 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 872 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 873 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 874 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 875 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 876 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 877 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 878 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 879 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 880 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 881 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 882 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 883 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 884 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 885 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 886 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 887 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 888 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 889 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 890 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 891 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 892 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 893 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 894 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 895 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 896 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 897 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 898 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 899 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 900 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 901 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 902 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 903 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 904 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 905 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 906 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 907 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 908 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 909 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 910 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 911 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 912 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 913 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 914 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 915 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 916 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 917 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 918 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 919 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 920 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 921 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 922 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 923 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 924 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 925 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 926 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 927 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 928 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 929 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 930 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 931 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 932 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 933 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 934 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 935 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 936 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 937 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 938 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 939 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 940 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 941 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 942 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 943 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 944 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 945 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 946 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 947 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 948 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 949 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 950 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 951 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 952 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 953 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 954 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 955 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 956 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 957 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 958 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 959 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 960 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 961 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 962 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 963 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 964 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 965 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 966 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 967 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 968 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 969 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 970 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 971 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 972 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 973 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 974 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 975 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 976 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 977 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 978 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 979 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 980 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 981 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 982 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 983 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 984 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 985 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 986 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 987 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 988 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 989 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 990 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 991 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 992 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 993 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 994 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 995 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 996 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 997 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 998 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 999 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1000 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1001 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1002 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1003 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1004 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1005 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1006 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1007 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1008 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1009 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1010 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1011 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1012 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1013 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1014 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1015 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1016 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1017 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1018 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1019 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1020 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1021 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1022 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1023 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1024 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1025 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1026 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1027 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1028 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1029 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1030 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1031 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1032 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1033 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1034 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1035 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1036 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1037 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1038 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1039 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1040 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1041 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1042 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1043 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1044 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1045 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1046 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1047 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1048 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1049 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1050 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1051 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1052 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1053 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1054 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1055 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1056 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1057 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1058 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1059 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1060 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1061 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1062 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1063 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1064 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1065 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1066 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1067 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1068 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1069 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1070 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1071 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1072 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1073 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1074 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1075 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1076 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1077 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1078 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1079 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1080 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1081 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1082 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1083 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1084 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1085 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1086 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1087 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1088 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1089 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1090 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1091 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1092 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1093 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1094 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1095 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1096 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1097 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1098 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1099 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1100 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1101 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1102 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1103 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1104 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1105 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1106 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1107 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1108 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1109 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1110 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1111 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1112 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1113 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1114 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1115 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1116 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1117 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1118 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1119 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1120 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1121 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1122 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1123 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1124 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1125 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1126 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1127 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1128 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1129 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1130 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1131 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1132 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1133 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1134 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1135 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1136 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1137 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1138 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1139 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1140 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1141 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1142 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1143 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1144 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1145 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1146 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1147 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1148 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1149 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1150 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1151 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1152 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1153 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1154 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1155 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1156 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1157 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1158 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1159 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1160 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1161 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1162 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1163 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1164 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1165 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1166 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1167 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1168 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1169 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1170 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1171 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1172 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1173 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1174 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1175 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1176 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1177 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1178 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1179 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1180 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1181 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1182 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1183 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1184 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1185 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1186 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1187 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1188 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1189 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1190 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1191 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1192 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1193 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1194 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1195 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1196 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1197 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1198 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1199 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1200 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1201 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1202 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1203 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1204 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1205 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1206 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1207 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1208 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1209 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1210 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1211 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1212 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1213 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1214 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1215 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1216 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1217 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1218 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1219 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1220 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1221 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1222 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1223 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1224 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1225 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1226 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1227 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1228 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1229 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1230 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1231 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1232 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1233 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1234 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1235 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1236 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1237 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1238 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1239 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1240 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1241 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1242 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1243 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1244 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1245 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1246 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1247 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1248 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1249 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1250 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1251 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1252 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1253 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1254 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1255 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1256 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1257 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1258 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1259 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1260 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1261 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1262 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1263 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1264 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1265 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1266 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1267 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1268 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1269 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1270 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1271 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1272 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1273 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1274 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1275 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1276 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1277 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1278 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1279 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1280 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1281 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1282 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1283 of Sunrise on the Reaping.txt\n",
      "Tokenizing chunk 1284 of Sunrise on the Reaping.txt\n",
      "Finished processing Sunrise on the Reaping.txt for embeddings.\n"
     ]
    }
   ],
   "source": [
    "from modules.accessor import add_embedding\n",
    "from modules.embedding_tracking import mark_file_processed, is_file_processed\n",
    "\n",
    "filenames = os.listdir(PROCESSED_BOOKS_FOLDER_PATH)\n",
    "\n",
    "for filename in filenames:\n",
    "    with open(os.path.join(PROCESSED_BOOKS_FOLDER_PATH, filename), \"r\", encoding=\"utf-8\") as file:\n",
    "        text = file.read()\n",
    "        print(f\"Tokenizing {filename}\")\n",
    "        \n",
    "        if not is_file_processed(filename, \"full_text_bert_truncated\"):\n",
    "            # Truncated BERT embeddings\n",
    "            token_embeddings = generate_bert_embeddings(text, truncate=True)\n",
    "            \n",
    "            try:\n",
    "                add_embedding(\n",
    "                    embeddings=token_embeddings,\n",
    "                    document=filename,\n",
    "                    custom_suffix=\"full_text_bert_truncated\",\n",
    "                    metadata=None\n",
    "                )\n",
    "                mark_file_processed(filename, \"full_text_bert_truncated\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error adding embedding for {filename}: {e}\")\n",
    "                print(\"Embedding Spec:\", len(token_embeddings))\n",
    "        \n",
    "        if not is_file_processed(filename, \"chunked_text_bert\"):\n",
    "            # Chunked BERT embeddings\n",
    "            chunk_size = 512  # BERT's max input size\n",
    "            chunks = [text[i:i+chunk_size] for i in range(0, len(text), chunk_size)]\n",
    "            for idx in range(len(chunks)):\n",
    "                print(f\"Tokenizing chunk {idx+1} of {filename}\")\n",
    "                token_embeddings = generate_bert_embeddings(chunks[idx], truncate=False)\n",
    "                \n",
    "                try:\n",
    "                    add_embedding(\n",
    "                        embeddings=token_embeddings,\n",
    "                        document=filename,\n",
    "                        custom_suffix=\"chunked_text_bert\",\n",
    "                        metadata={\"chunk_index\": idx + 1}\n",
    "                    )\n",
    "                except Exception as e:\n",
    "                    print(f\"Error adding embedding for chunk {idx+1} of {filename}: {e}\")\n",
    "                    print(\"Embedding Spec:\", len(token_embeddings))\n",
    "                    break\n",
    "            mark_file_processed(filename, \"chunked_text_bert\")\n",
    "            \n",
    "    print(f\"Finished processing {filename} for embeddings.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cfea5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection 'dim_768_collection_full_text_bert_truncated' deleted.\n",
      "Collection 'dim_768_collection_chunked_text_bert' deleted.\n"
     ]
    }
   ],
   "source": [
    "# if need to remove collections from the database\n",
    "# from modules.accessor import list_collections, delete_collection\n",
    "\n",
    "# for i in list_collections():\n",
    "#     delete_collection(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d35fb2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available collections: ['dim_768_collection_chunked_text_bert', 'dim_768_collection_full_text_bert_truncated']\n",
      "[['All Fours (Miranda July).txt', 'Sunrise on the Reaping.txt', 'Sunrise on the Reaping.txt', 'All Fours (Miranda July).txt', 'Sunrise on the Reaping.txt'], ['All Fours (Miranda July).txt', 'Sunrise on the Reaping.txt', 'All Fours (Miranda July).txt', 'Sunrise on the Reaping.txt', 'All Fours (Miranda July).txt'], ['All Fours (Miranda July).txt', 'All Fours (Miranda July).txt', 'All Fours (Miranda July).txt', 'All Fours (Miranda July).txt', 'Sunrise on the Reaping.txt'], ['All Fours (Miranda July).txt', 'Sunrise on the Reaping.txt', 'All Fours (Miranda July).txt', 'Sunrise on the Reaping.txt', 'All Fours (Miranda July).txt'], ['All Fours (Miranda July).txt', 'Sunrise on the Reaping.txt', 'Sunrise on the Reaping.txt', 'Sunrise on the Reaping.txt', 'Sunrise on the Reaping.txt'], ['All Fours (Miranda July).txt', 'All Fours (Miranda July).txt', 'All Fours (Miranda July).txt', 'Sunrise on the Reaping.txt', 'Sunrise on the Reaping.txt'], ['All Fours (Miranda July).txt', 'All Fours (Miranda July).txt', 'Sunrise on the Reaping.txt', 'Sunrise on the Reaping.txt', 'Sunrise on the Reaping.txt'], ['All Fours (Miranda July).txt', 'All Fours (Miranda July).txt', 'All Fours (Miranda July).txt', 'Sunrise on the Reaping.txt', 'Sunrise on the Reaping.txt'], ['All Fours (Miranda July).txt', 'All Fours (Miranda July).txt', 'All Fours (Miranda July).txt', 'All Fours (Miranda July).txt', 'All Fours (Miranda July).txt'], ['Sunrise on the Reaping.txt', 'Sunrise on the Reaping.txt', 'Sunrise on the Reaping.txt', 'Sunrise on the Reaping.txt', 'Sunrise on the Reaping.txt'], ['All Fours (Miranda July).txt', 'All Fours (Miranda July).txt', 'All Fours (Miranda July).txt', 'All Fours (Miranda July).txt', 'All Fours (Miranda July).txt']]\n"
     ]
    }
   ],
   "source": [
    "from modules.accessor import list_collections, query_embedding\n",
    "\n",
    "available_collections = list_collections()\n",
    "print(f\"Available collections: {available_collections}\")\n",
    "\n",
    "query_result = query_embedding(\n",
    "    query=generate_bert_embeddings(\"What book has the word Sunrise in it?\"),\n",
    "    custom_suffix=\"full_text_bert_truncated\",\n",
    "    n_results=5\n",
    ")\n",
    "print(query_result['documents'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8681c0d3",
   "metadata": {},
   "source": [
    "## Process Movie Transcripts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
