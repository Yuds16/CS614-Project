{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"d3eVXvac9xbU","colab":{"base_uri":"https://localhost:8080/"},"outputId":"d1303bea-5e8c-429a-eb9a-4b38c3ea195c","executionInfo":{"status":"ok","timestamp":1750733039963,"user_tz":-480,"elapsed":25822,"user":{"displayName":"SU, XINGZE _","userId":"01580346516857497041"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: hf_xet in /usr/local/lib/python3.11/dist-packages (1.1.3)\n","Requirement already satisfied: trl in /usr/local/lib/python3.11/dist-packages (0.19.0)\n","Requirement already satisfied: accelerate>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from trl) (1.7.0)\n","Requirement already satisfied: datasets>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from trl) (3.6.0)\n","Requirement already satisfied: transformers>=4.51.0 in /usr/local/lib/python3.11/dist-packages (from trl) (4.52.4)\n","Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate>=1.4.0->trl) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=1.4.0->trl) (24.2)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate>=1.4.0->trl) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate>=1.4.0->trl) (6.0.2)\n","Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=1.4.0->trl) (2.6.0+cu124)\n","Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=1.4.0->trl) (0.33.0)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate>=1.4.0->trl) (0.5.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (3.18.0)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (18.1.0)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (0.3.7)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (2.2.2)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (2.32.3)\n","Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (4.67.1)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (3.5.0)\n","Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (0.70.15)\n","Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (2025.3.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.51.0->trl) (2024.11.6)\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.51.0->trl) (0.21.1)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (3.11.15)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate>=1.4.0->trl) (4.14.0)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate>=1.4.0->trl) (1.1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (2025.6.15)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (3.1.6)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (12.4.127)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (12.4.5.8)\n","Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (11.2.1.3)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (10.3.5.147)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (11.6.1.9)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (12.3.1.170)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (12.4.127)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (12.4.127)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate>=1.4.0->trl) (1.3.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=3.0.0->trl) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=3.0.0->trl) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=3.0.0->trl) (2025.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (1.3.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (1.7.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (6.4.4)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (0.3.2)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (1.20.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=3.0.0->trl) (1.17.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate>=1.4.0->trl) (3.0.2)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.0)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.6.15)\n","Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (2.18.0)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.4.0)\n","Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.73.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (3.8)\n","Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (2.0.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorboard) (24.2)\n","Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (5.29.5)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (75.2.0)\n","Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.17.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (3.1.3)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard) (3.0.2)\n","Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.11/dist-packages (0.46.0)\n","Requirement already satisfied: torch<3,>=2.2 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.6.0+cu124)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.0.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.18.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (4.14.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.5.8)\n","Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (11.2.1.3)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (10.3.5.147)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (11.6.1.9)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.3.1.170)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.2->bitsandbytes) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.2->bitsandbytes) (3.0.2)\n","Requirement already satisfied: transformers_stream_generator in /usr/local/lib/python3.11/dist-packages (0.0.5)\n","Requirement already satisfied: transformers>=4.26.1 in /usr/local/lib/python3.11/dist-packages (from transformers_stream_generator) (4.52.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers>=4.26.1->transformers_stream_generator) (3.18.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.26.1->transformers_stream_generator) (0.33.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.26.1->transformers_stream_generator) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.26.1->transformers_stream_generator) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.26.1->transformers_stream_generator) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.26.1->transformers_stream_generator) (2024.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers>=4.26.1->transformers_stream_generator) (2.32.3)\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.26.1->transformers_stream_generator) (0.21.1)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.26.1->transformers_stream_generator) (0.5.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.26.1->transformers_stream_generator) (4.67.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers>=4.26.1->transformers_stream_generator) (2025.3.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers>=4.26.1->transformers_stream_generator) (4.14.0)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers>=4.26.1->transformers_stream_generator) (1.1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.26.1->transformers_stream_generator) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.26.1->transformers_stream_generator) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.26.1->transformers_stream_generator) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.26.1->transformers_stream_generator) (2025.6.15)\n"]}],"source":["!pip install hf_xet\n","!pip install trl\n","!pip install --upgrade transformers\n","!pip install tensorboard\n","!pip install -U bitsandbytes\n","!pip install transformers_stream_generator"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"7rPWGTcECKk5","executionInfo":{"status":"ok","timestamp":1750733050566,"user_tz":-480,"elapsed":10601,"user":{"displayName":"SU, XINGZE _","userId":"01580346516857497041"}}},"outputs":[],"source":["import os\n","from datasets import load_dataset, concatenate_datasets, Dataset\n","import torch\n","from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments\n","from peft import LoraConfig, get_peft_model\n","from trl import SFTTrainer, SFTConfig"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","%cd /content/drive/MyDrive/SMU_MITB_LLM/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3_LvcX8qsKoX","executionInfo":{"status":"ok","timestamp":1750733068200,"user_tz":-480,"elapsed":1287,"user":{"displayName":"SU, XINGZE _","userId":"01580346516857497041"}},"outputId":"842bdaa1-881b-4fa7-ba2e-89251e18a6eb"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/MyDrive/SMU_MITB_LLM\n"]}]},{"cell_type":"code","execution_count":5,"metadata":{"id":"GBHluaY8CKiV","executionInfo":{"status":"ok","timestamp":1750733069006,"user_tz":-480,"elapsed":51,"user":{"displayName":"SU, XINGZE _","userId":"01580346516857497041"}}},"outputs":[],"source":["# load tuning sets for <Sunrise on the Reaping>\n","sunrise_train_path = './reasoned_qa_output/sunrise_train_data.json'\n","sunrise_val_path = './reasoned_qa_output/sunrise_val_data.json'\n","sunrise_test_path = './reasoned_qa_output/sunrise_test_data.json'\n","\n","sunrise_train_datasets = Dataset.from_json(sunrise_train_path)\n","sunrise_val_datasets = Dataset.from_json(sunrise_val_path)\n","sunrise_test_datasets = Dataset.from_json(sunrise_test_path)"]},{"cell_type":"code","source":["# load tuning sets for <All Fours>\n","allfours_train_path = './reasoned_qa_output/allfours_train_data.json'\n","allfours_val_path = './reasoned_qa_output/allfours_val_data.json'\n","allfours_test_path = './reasoned_qa_output/allfours_test_data.json'\n","\n","allfours_train_datasets = Dataset.from_json(allfours_train_path)\n","allfours_val_datasets = Dataset.from_json(allfours_val_path)\n","allfours_test_datasets = Dataset.from_json(allfours_test_path)"],"metadata":{"id":"BdlnK1TAtkGr","executionInfo":{"status":"ok","timestamp":1750733070551,"user_tz":-480,"elapsed":14,"user":{"displayName":"SU, XINGZE _","userId":"01580346516857497041"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# Combine two books together\n","train_set = concatenate_datasets([sunrise_train_datasets, allfours_train_datasets])\n","val_set = concatenate_datasets([sunrise_val_datasets, allfours_val_datasets])\n","test_set = concatenate_datasets([sunrise_test_datasets, allfours_test_datasets])"],"metadata":{"id":"JKDU0_vwuJa8","executionInfo":{"status":"ok","timestamp":1750733072406,"user_tz":-480,"elapsed":14,"user":{"displayName":"SU, XINGZE _","userId":"01580346516857497041"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["train_set"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QgyeKa968r5a","executionInfo":{"status":"ok","timestamp":1750733072856,"user_tz":-480,"elapsed":2,"user":{"displayName":"SU, XINGZE _","userId":"01580346516857497041"}},"outputId":"176ec1e8-b94c-4df4-b79d-1c68981a722b"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Dataset({\n","    features: ['Question', 'Answer', 'Reasoning'],\n","    num_rows: 958\n","})"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["val_set"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wSk8KY0E9zRQ","executionInfo":{"status":"ok","timestamp":1750733073075,"user_tz":-480,"elapsed":3,"user":{"displayName":"SU, XINGZE _","userId":"01580346516857497041"}},"outputId":"6cfe4b87-89d6-468f-f1e1-03137a14fd97"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Dataset({\n","    features: ['Question', 'Answer', 'Reasoning'],\n","    num_rows: 120\n","})"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["test_set"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VTz4Y8Md9zOO","executionInfo":{"status":"ok","timestamp":1750733073385,"user_tz":-480,"elapsed":14,"user":{"displayName":"SU, XINGZE _","userId":"01580346516857497041"}},"outputId":"ad989526-08ad-47d5-d229-c4fd9a155779"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Dataset({\n","    features: ['Question', 'Answer', 'Reasoning'],\n","    num_rows: 120\n","})"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["print(train_set[\"Question\"][-1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Xy3qVUouuL8y","executionInfo":{"status":"ok","timestamp":1750733075183,"user_tz":-480,"elapsed":15,"user":{"displayName":"SU, XINGZE _","userId":"01580346516857497041"}},"outputId":"967bed71-fb82-4525-8bdd-48bd145bbe33"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["What trick does Jordi teach the protagonist to help stop thinking about Davey?\n"]}]},{"cell_type":"code","source":["from huggingface_hub import notebook_login\n","notebook_login()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17,"referenced_widgets":["40a10b89b1794ea6b585a6f2743a344f","40f1a1d3d7664facafa6edcba82a652f","1b7b16de18b24fda8951663e873eb312","907b534bcefe45d8952ba2f84c78a7c7","9a11e431da34472494c3e4bad546308e","06c23b83814244848e4b6c1409782b6f","dc0dc9c99b44403f9f56fb52d49cb373","b9347bfa4fca4a32acea784759f1e930","23f1942b0dd448d6b6009b9b21b3e9be","379b28d65f824727a695df2137e21801","4a5ac4f55d8c4e5e9aa6da179cbe60fb","7ff8750ed05d437382b4a6d6180071ab","eed2b53a8b3d48ac888686a507ee5d2f","9f1a80105653403fbb2fc6349a0064b7","fb83214543e847ae9172bfdb5f1dff12","eee5c07f2b5742d7ae87193433b15019","25dbd57656ca4f4c813a794b7eb51ded","89ec70f68da84cd9a32bfdd0c841ede2","6870858d4f6b442bb147f44a3d4887c5","c69e16ce52e64a0bb64af9c68cb39eea"]},"id":"S_m-0VCVuPCw","executionInfo":{"status":"ok","timestamp":1750733075616,"user_tz":-480,"elapsed":15,"user":{"displayName":"SU, XINGZE _","userId":"01580346516857497041"}},"outputId":"78fe7a1c-8c42-468a-bcfb-fa088eb7b0e8"},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":["VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"40a10b89b1794ea6b585a6f2743a344f"}},"metadata":{}}]},{"cell_type":"code","source":["# Load Reasoning LLM\n","gemma_model = 'google/gemma-2b'\n","# Load the specified tokenizer for the model to ensure consistency\n","tokenizer = AutoTokenizer.from_pretrained(gemma_model)"],"metadata":{"id":"BwHwvGL6uNol","executionInfo":{"status":"ok","timestamp":1750733085464,"user_tz":-480,"elapsed":1619,"user":{"displayName":"SU, XINGZE _","userId":"01580346516857497041"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["# load model\n","model = AutoModelForCausalLM.from_pretrained(\n","    gemma_model,\n","    device_map=\"auto\"  # instructs the transformers library to automatically distribute the model's layer cross available decives to optimise memory usage\n",")\n","model.config.use_cache = False"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["1b22405c0ed642c48ab8a3a3c4ecc25d","5319008cf0434ec48604dd5d584be862","cfe9fe52d23c4e2c83c45230a7d4e836","74b8a752d37b4810a4355e1d2ed338a6","18910dbdd6fe41c2b8605e646bc6666a","005f8dddb7644f548cac2855464a2172","8ae148f64ca84e12afa7a15e1d6630cc","0c3993f819f245e39fd21ddf325025b7","94cd60e792e4468598082e68c3f17915","329681ec6a314d7ea8daa8e932907c5c","831f5c63227a425b8208f64c6e3ca6f4"]},"id":"q4zos9T7vqAB","executionInfo":{"status":"ok","timestamp":1750733090222,"user_tz":-480,"elapsed":3183,"user":{"displayName":"SU, XINGZE _","userId":"01580346516857497041"}},"outputId":"0bc57a9c-13fd-45d3-8318-616b3da350b1"},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b22405c0ed642c48ab8a3a3c4ecc25d"}},"metadata":{}}]},{"cell_type":"code","source":["lora_config = LoraConfig(\n","    r=16,\n","    lora_alpha=32,\n","    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n","    bias=\"none\",\n","    lora_dropout=0.05,\n","    task_type=\"CAUSAL_LM\",\n",")\n","\n","model = get_peft_model(model, lora_config)\n","model.print_trainable_parameters()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"maoY7nw7z5xG","executionInfo":{"status":"ok","timestamp":1750733108852,"user_tz":-480,"elapsed":543,"user":{"displayName":"SU, XINGZE _","userId":"01580346516857497041"}},"outputId":"764dc292-527f-4e33-9423-88a1a5e13e41"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["trainable params: 19,611,648 || all params: 2,525,784,064 || trainable%: 0.7765\n"]}]},{"cell_type":"code","source":["def formatting_prompts_func(examples):\n","    texts = []\n","    for question, answer, reasoning_list in zip(examples[\"Question\"], examples[\"Answer\"], examples[\"Reasoning\"]):\n","        reasoning_str = \"\\n\".join([f\"Step {i+1}: {step}\" for i, step in enumerate(reasoning_list)])\n","        formatted_text = (\n","            f\"### Question:\\n{question}\\n\\n\"\n","            f\"### Thought Process:\\n\"\n","            f\"{reasoning_str}\\n\\n\"\n","            f\"### Answer:\\n{answer}\"\n","        )\n","        texts.append(formatted_text)\n","    return {\"text\": texts}"],"metadata":{"id":"uNqeA1xY0QjT","executionInfo":{"status":"ok","timestamp":1750733114923,"user_tz":-480,"elapsed":11,"user":{"displayName":"SU, XINGZE _","userId":"01580346516857497041"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["train_dataset_formatted = train_set.map(\n","    formatting_prompts_func,\n","    batched=True,\n","    remove_columns=train_set.column_names\n",")\n","validation_dataset_formatted = val_set.map(\n","    formatting_prompts_func,\n","    batched=True,\n","    remove_columns=val_set.column_names\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81,"referenced_widgets":["4658ebe753924c0d8c6740f6f14c7bde","2223be318d004b5a9edb413536708fe2","561aea7909444dd7bc27afc5576fea9f","00321108acbf49208725b47ccbb9a7ea","f0a464ee653047ed930706e0ef27981d","9bb49c37888742b483fc323bbf7ea4a3","e78f3450efdc4a73adadbf17de8c651e","c2b7d5d466444c46bcd3b77199ce508c","3b72e13b13264b7a8b757426fa121c71","b0f9c9b50988461b859375826ef58afb","465589a9b37f4f6f9ba0e52ec87c8599","336385f0ff8e447f95f84b4b624dbacd","84eeec6527a04792b674b7b169b37440","870a5992873d471d96f755cf11cd1414","7ffefcb7eccc41b39007527ff8ac8b6b","04058eaf525d49a282ead7e8635fb4f6","833d08681e484594b030069ccc18129f","974fdaf5365a4334bc34773449d9dca6","3e255235e7dd4c9e8d96b4e4c75d08f0","b21fd5f618dc407e8a235ec40151ea84","e0e8defadfce4d1ea24c7ee5c66bad54","8af4b0b432bd4cf2a834579391750f9d"]},"id":"WDEwh5kY0XrM","executionInfo":{"status":"ok","timestamp":1750733117105,"user_tz":-480,"elapsed":58,"user":{"displayName":"SU, XINGZE _","userId":"01580346516857497041"}},"outputId":"45a40da0-63d4-4396-c7ae-03baead89855"},"execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/958 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4658ebe753924c0d8c6740f6f14c7bde"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/120 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"336385f0ff8e447f95f84b4b624dbacd"}},"metadata":{}}]},{"cell_type":"code","source":["print(train_dataset_formatted['text'][-1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r4kwBYd40dnE","executionInfo":{"status":"ok","timestamp":1750733118801,"user_tz":-480,"elapsed":38,"user":{"displayName":"SU, XINGZE _","userId":"01580346516857497041"}},"outputId":"98b6fa60-0520-45c9-ae73-b69dd3169f74"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["### Question:\n","What trick does Jordi teach the protagonist to help stop thinking about Davey?\n","\n","### Thought Process:\n","Step 1: During their meeting, Jordi demonstrates a technique she used to quit smoking.\n","Step 2: The protagonist snaps a rubber band on her wrist each time she thinks of Davey.\n","Step 3: This method aims to reduce obsessive thoughts through punishment.\n","\n","### Answer:\n","Jordi teaches her to use a rubber band for negative reinforcement whenever she thinks about him.\n"]}]},{"cell_type":"code","source":["import inspect\n","from trl import SFTTrainer\n","print(inspect.signature(SFTTrainer.__init__))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4pRRU7P5EqXu","executionInfo":{"status":"ok","timestamp":1750733120110,"user_tz":-480,"elapsed":11,"user":{"displayName":"SU, XINGZE _","userId":"01580346516857497041"}},"outputId":"35e31d79-b05e-4edc-c684-0a666b24f7bd"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["(self, model: Union[str, torch.nn.modules.module.Module, transformers.modeling_utils.PreTrainedModel], args: Union[trl.trainer.sft_config.SFTConfig, transformers.training_args.TrainingArguments, NoneType] = None, data_collator: Optional[transformers.data.data_collator.DataCollator] = None, train_dataset: Union[datasets.arrow_dataset.Dataset, datasets.iterable_dataset.IterableDataset, NoneType] = None, eval_dataset: Union[datasets.arrow_dataset.Dataset, dict[str, datasets.arrow_dataset.Dataset], NoneType] = None, processing_class: Union[transformers.tokenization_utils_base.PreTrainedTokenizerBase, transformers.image_processing_utils.BaseImageProcessor, transformers.feature_extraction_utils.FeatureExtractionMixin, transformers.processing_utils.ProcessorMixin, NoneType] = None, compute_loss_func: Optional[Callable] = None, compute_metrics: Optional[Callable[[transformers.trainer_utils.EvalPrediction], dict]] = None, callbacks: Optional[list[transformers.trainer_callback.TrainerCallback]] = None, optimizers: tuple[typing.Optional[torch.optim.optimizer.Optimizer], typing.Optional[torch.optim.lr_scheduler.LambdaLR]] = (None, None), optimizer_cls_and_kwargs: Optional[tuple[type[torch.optim.optimizer.Optimizer], dict[str, Any]]] = None, preprocess_logits_for_metrics: Optional[Callable[[torch.Tensor, torch.Tensor], torch.Tensor]] = None, peft_config: Optional[ForwardRef('PeftConfig')] = None, formatting_func: Optional[Callable[[dict], str]] = None)\n"]}]},{"cell_type":"code","source":["\n","sft_config = SFTConfig(\n","    output_dir=\"./results\", # From TrainingArguments\n","    num_train_epochs=3, # From TrainingArguments\n","    per_device_train_batch_size=4, # From TrainingArguments\n","    per_device_eval_batch_size=4,\n","    warmup_steps=500,\n","    gradient_accumulation_steps=1, # From TrainingArguments\n","    learning_rate=2e-4, # From TrainingArguments\n","    logging_steps=10, # From TrainingArguments\n","    save_steps=500, # From TrainingArguments\n","    # Add SFT-specific parameters here:\n","    max_seq_length=128, # Now correctly placed in SFTConfig\n","    dataset_text_field=\"text\", # Important for SFTTrainer\n","    packing=True, # Recommended for efficient SFT\n","    optim=\"adafactor\",\n","    fp16=True, # For mixed precision, if SFTConfig handles this\n",")\n","\n","\n","trainer = SFTTrainer(\n","    model=model,\n","    processing_class=tokenizer, # Keep this, as it's separate from args\n","    train_dataset=train_dataset_formatted,\n","    eval_dataset=validation_dataset_formatted,\n","    peft_config=lora_config,\n","    args=sft_config, # <-- Pass the SFTConfig object here!\n","    # formatting_func=formatting_func, # If you have a custom formatting function\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wt-mhG_yGFTz","executionInfo":{"status":"ok","timestamp":1750733191952,"user_tz":-480,"elapsed":1035,"user":{"displayName":"SU, XINGZE _","userId":"01580346516857497041"}},"outputId":"916b52ae-f4e6-4806-91da-4c850cb5764e"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stderr","text":["average_tokens_across_devices is set to True but it is invalid when world size is1. Turn it to False automatically.\n","/usr/local/lib/python3.11/dist-packages/trl/trainer/sft_trainer.py:404: UserWarning: Padding-free training is enabled, but the attention implementation is not set to 'flash_attention_2'. Padding-free training flattens batches into a single sequence, and 'flash_attention_2' is the only known attention mechanism that reliably supports this. Using other implementations may lead to unexpected behavior. To ensure compatibility, set `attn_implementation='flash_attention_2'` in the model configuration, or verify that your attention mechanism can handle flattened sequences.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/trl/trainer/sft_trainer.py:450: UserWarning: You are using packing, but the attention implementation is not set to 'flash_attention_2'. Packing flattens batches into a single sequence, and 'flash_attention_2' is the only known attention mechanism that reliably supports this. Using other implementations may lead to cross-contamination between batches. To avoid this, either disable packing by setting `packing=False`, or set `attn_implementation='flash_attention_2'` in the model configuration.\n","  warnings.warn(\n","No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"]}]},{"cell_type":"code","source":["import torch\n","torch.cuda.empty_cache()"],"metadata":{"id":"5zVPcOkCBtFs","executionInfo":{"status":"ok","timestamp":1750733193026,"user_tz":-480,"elapsed":14,"user":{"displayName":"SU, XINGZE _","userId":"01580346516857497041"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["print(\"Model Tuning Start...\")\n","trainer.train()\n","print(\"Model Tuning Completed\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"5Lk5xBm60evP","executionInfo":{"status":"ok","timestamp":1750733430905,"user_tz":-480,"elapsed":237408,"user":{"displayName":"SU, XINGZE _","userId":"01580346516857497041"}},"outputId":"c127d167-af48-47a0-c868-72242b8e59b6"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["Model Tuning Start...\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='720' max='720' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [720/720 03:56, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>2.758400</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>2.627800</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>2.585300</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>2.468200</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>2.459300</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>2.369100</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>2.199600</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>2.087200</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>2.039300</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>1.850600</td>\n","    </tr>\n","    <tr>\n","      <td>110</td>\n","      <td>1.994400</td>\n","    </tr>\n","    <tr>\n","      <td>120</td>\n","      <td>1.956500</td>\n","    </tr>\n","    <tr>\n","      <td>130</td>\n","      <td>1.959600</td>\n","    </tr>\n","    <tr>\n","      <td>140</td>\n","      <td>1.919300</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>1.958700</td>\n","    </tr>\n","    <tr>\n","      <td>160</td>\n","      <td>1.781300</td>\n","    </tr>\n","    <tr>\n","      <td>170</td>\n","      <td>1.893500</td>\n","    </tr>\n","    <tr>\n","      <td>180</td>\n","      <td>1.838500</td>\n","    </tr>\n","    <tr>\n","      <td>190</td>\n","      <td>1.738000</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>1.704500</td>\n","    </tr>\n","    <tr>\n","      <td>210</td>\n","      <td>1.713400</td>\n","    </tr>\n","    <tr>\n","      <td>220</td>\n","      <td>1.816500</td>\n","    </tr>\n","    <tr>\n","      <td>230</td>\n","      <td>1.887900</td>\n","    </tr>\n","    <tr>\n","      <td>240</td>\n","      <td>1.660900</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>1.661900</td>\n","    </tr>\n","    <tr>\n","      <td>260</td>\n","      <td>1.566200</td>\n","    </tr>\n","    <tr>\n","      <td>270</td>\n","      <td>1.713300</td>\n","    </tr>\n","    <tr>\n","      <td>280</td>\n","      <td>1.592000</td>\n","    </tr>\n","    <tr>\n","      <td>290</td>\n","      <td>1.575700</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>1.670000</td>\n","    </tr>\n","    <tr>\n","      <td>310</td>\n","      <td>1.513700</td>\n","    </tr>\n","    <tr>\n","      <td>320</td>\n","      <td>1.619600</td>\n","    </tr>\n","    <tr>\n","      <td>330</td>\n","      <td>1.522400</td>\n","    </tr>\n","    <tr>\n","      <td>340</td>\n","      <td>1.463600</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>1.585100</td>\n","    </tr>\n","    <tr>\n","      <td>360</td>\n","      <td>1.471500</td>\n","    </tr>\n","    <tr>\n","      <td>370</td>\n","      <td>1.333100</td>\n","    </tr>\n","    <tr>\n","      <td>380</td>\n","      <td>1.481200</td>\n","    </tr>\n","    <tr>\n","      <td>390</td>\n","      <td>1.622600</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>1.629800</td>\n","    </tr>\n","    <tr>\n","      <td>410</td>\n","      <td>1.709500</td>\n","    </tr>\n","    <tr>\n","      <td>420</td>\n","      <td>1.591500</td>\n","    </tr>\n","    <tr>\n","      <td>430</td>\n","      <td>1.607500</td>\n","    </tr>\n","    <tr>\n","      <td>440</td>\n","      <td>1.649700</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>1.479500</td>\n","    </tr>\n","    <tr>\n","      <td>460</td>\n","      <td>1.386200</td>\n","    </tr>\n","    <tr>\n","      <td>470</td>\n","      <td>1.424000</td>\n","    </tr>\n","    <tr>\n","      <td>480</td>\n","      <td>1.434500</td>\n","    </tr>\n","    <tr>\n","      <td>490</td>\n","      <td>1.278100</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>1.096600</td>\n","    </tr>\n","    <tr>\n","      <td>510</td>\n","      <td>1.205600</td>\n","    </tr>\n","    <tr>\n","      <td>520</td>\n","      <td>1.242900</td>\n","    </tr>\n","    <tr>\n","      <td>530</td>\n","      <td>1.165500</td>\n","    </tr>\n","    <tr>\n","      <td>540</td>\n","      <td>1.234600</td>\n","    </tr>\n","    <tr>\n","      <td>550</td>\n","      <td>1.150800</td>\n","    </tr>\n","    <tr>\n","      <td>560</td>\n","      <td>1.287500</td>\n","    </tr>\n","    <tr>\n","      <td>570</td>\n","      <td>1.141600</td>\n","    </tr>\n","    <tr>\n","      <td>580</td>\n","      <td>1.288700</td>\n","    </tr>\n","    <tr>\n","      <td>590</td>\n","      <td>1.096900</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>1.248800</td>\n","    </tr>\n","    <tr>\n","      <td>610</td>\n","      <td>1.138400</td>\n","    </tr>\n","    <tr>\n","      <td>620</td>\n","      <td>1.060700</td>\n","    </tr>\n","    <tr>\n","      <td>630</td>\n","      <td>1.119800</td>\n","    </tr>\n","    <tr>\n","      <td>640</td>\n","      <td>1.229600</td>\n","    </tr>\n","    <tr>\n","      <td>650</td>\n","      <td>1.260700</td>\n","    </tr>\n","    <tr>\n","      <td>660</td>\n","      <td>1.103300</td>\n","    </tr>\n","    <tr>\n","      <td>670</td>\n","      <td>1.131300</td>\n","    </tr>\n","    <tr>\n","      <td>680</td>\n","      <td>1.119900</td>\n","    </tr>\n","    <tr>\n","      <td>690</td>\n","      <td>1.126300</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>1.099500</td>\n","    </tr>\n","    <tr>\n","      <td>710</td>\n","      <td>1.006900</td>\n","    </tr>\n","    <tr>\n","      <td>720</td>\n","      <td>1.120800</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The get_url method is deprecated and will be removed in a future release. Please use `run.url` instead.\n"]},{"output_type":"stream","name":"stdout","text":["Model Tuning Completed\n"]}]},{"cell_type":"code","source":["# Save LoAR Adapter\n","output_model_path = \"./LoRA_Gemma\"\n","trainer.save_model(output_model_path)\n","print(f\"Fine-tuned LoRA Adapter saved to: {output_model_path}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nx56FiBD0etC","executionInfo":{"status":"ok","timestamp":1750733435904,"user_tz":-480,"elapsed":4998,"user":{"displayName":"SU, XINGZE _","userId":"01580346516857497041"}},"outputId":"2a8695c6-39c1-4ec5-d131-970af408e952"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["Fine-tuned LoRA Adapter saved to: ./LoRA_Gemma\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"uX0CcxVDssfW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install rouge_score sacrebleu"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2CAn2Y9ct5_E","executionInfo":{"status":"ok","timestamp":1750733444169,"user_tz":-480,"elapsed":5618,"user":{"displayName":"SU, XINGZE _","userId":"01580346516857497041"}},"outputId":"2629793c-8312-4c19-eaec-32c33ecd7578"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting rouge_score\n","  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting sacrebleu\n","  Downloading sacrebleu-2.5.1-py3-none-any.whl.metadata (51 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.4.0)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge_score) (3.9.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rouge_score) (2.0.2)\n","Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.17.0)\n","Collecting portalocker (from sacrebleu)\n","  Downloading portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)\n","Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (2024.11.6)\n","Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (0.9.0)\n","Collecting colorama (from sacrebleu)\n","  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (5.4.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (8.2.1)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (1.5.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (4.67.1)\n","Downloading sacrebleu-2.5.1-py3-none-any.whl (104 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n","Downloading portalocker-3.2.0-py3-none-any.whl (22 kB)\n","Building wheels for collected packages: rouge_score\n","  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=a113ac6bab023ba65a1e365573999f0599d6cae11d05ddd2a6accd8460a00697\n","  Stored in directory: /root/.cache/pip/wheels/1e/19/43/8a442dc83660ca25e163e1bd1f89919284ab0d0c1475475148\n","Successfully built rouge_score\n","Installing collected packages: portalocker, colorama, sacrebleu, rouge_score\n","Successfully installed colorama-0.4.6 portalocker-3.2.0 rouge_score-0.1.2 sacrebleu-2.5.1\n"]}]},{"cell_type":"code","source":["from rouge_score import rouge_scorer\n","from sacrebleu.metrics import BLEU"],"metadata":{"id":"W6FXEHBrt4Zu","executionInfo":{"status":"ok","timestamp":1750733445682,"user_tz":-480,"elapsed":1501,"user":{"displayName":"SU, XINGZE _","userId":"01580346516857497041"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["from peft import PeftModel\n","from transformers import AutoModelForCausalLM, AutoTokenizer\n","\n","base_model_path = \"google/gemma-2b\"\n","lora_path = \"./LoRA_Gemma\"\n","\n","try:\n","    base_model = AutoModelForCausalLM.from_pretrained(\n","        base_model_path,\n","        trust_remote_code=True,\n","        device_map=\"auto\"\n","    )\n","\n","    model = PeftModel.from_pretrained(base_model, lora_path)\n","\n","    tokenizer = AutoTokenizer.from_pretrained(\n","        base_model_path,\n","        trust_remote_code=True\n","    )\n","\n","    print(\"LoRA Model Uploaded Successfully\")\n","\n","except Exception as e:\n","    print(f\"LoRA Model Uploaded Failed: {e}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["c5a5a1dd7690428482adbe67e8f929aa","33c39b3124044418be14d7d254e87118","8351e92ce22541c8b8357352fa17d99c","06b1e19032bc4f0f9a8f03b02c14aee9","0af55f1965934ad28e6d19f18a2e11eb","82af2515349044f4958546e78ab382e4","38b2508ccf6d49478eee55d29710bbd4","a666052503154da2920fcca8a753b7b5","d8f3cd0b68eb41bd8012c03de44669b4","76cf3c26dd564f68854821ab78fb2fec","0debd9e0e90b48bcbd84a6eec94e176a"]},"id":"R37WxI-g1TbD","executionInfo":{"status":"ok","timestamp":1750733450396,"user_tz":-480,"elapsed":4716,"user":{"displayName":"SU, XINGZE _","userId":"01580346516857497041"}},"outputId":"e649b88f-0179-4357-8848-c6f20a81b0cb"},"execution_count":31,"outputs":[{"output_type":"display_data","data":{"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c5a5a1dd7690428482adbe67e8f929aa"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["LoRA Model Uploaded Successfully\n"]}]},{"cell_type":"code","source":["def formatting_prompts_func(examples):\n","    texts = []\n","    for question, answer, reasoning_list in zip(examples[\"Question\"], examples[\"Answer\"], examples[\"Reasoning\"]):\n","        reasoning_str = \"\\n\".join([f\"Step {i+1}: {step}\" for i, step in enumerate(reasoning_list)])\n","        formatted_text = (\n","            f\"### Question:\\n{question}\\n\\n\"\n","            f\"### Thought Process:\\n\"\n","            f\"{reasoning_str}\\n\\n\"\n","            f\"### Answer:\\n{answer}\"\n","        )\n","        texts.append(formatted_text)\n","    return {\"text\": texts}"],"metadata":{"id":"65oEbhJ0trBd","executionInfo":{"status":"ok","timestamp":1750733456544,"user_tz":-480,"elapsed":11,"user":{"displayName":"SU, XINGZE _","userId":"01580346516857497041"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["def evaluate_model(model, tokenizer, dataset):\n","    model.eval()\n","    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n","    bleu = BLEU()\n","\n","    all_rouge_scores = {'rouge1': {'fmeasure': 0, 'precision': 0, 'recall': 0},\n","                'rouge2': {'fmeasure': 0, 'precision': 0, 'recall': 0},\n","                'rougeL': {'fmeasure': 0, 'precision': 0, 'recall': 0}}\n","    all_bleu_scores = 0\n","    count = 0\n","\n","    for example in dataset:\n","        prompt = example[\"text\"].split(\"### Answer:\")[0] + \"### Answer:\"\n","        reference = example[\"text\"].split(\"### Answer:\")[1].strip()\n","\n","        input_data = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True)\n","        input_ids = input_data.input_ids.to(model.device)\n","        attention_mask = input_data.attention_mask.to(model.device)\n","\n","        with torch.no_grad():\n","            outputs = model.generate(\n","                input_ids,\n","                max_new_tokens=100,\n","                num_return_sequences=1,\n","                pad_token_id=tokenizer.eos_token_id,\n","                attention_mask = attention_mask\n","            )\n","\n","        generated_text = tokenizer.decode(outputs[0][len(input_ids[0]):], skip_special_tokens=True).strip()\n","\n","        rouge_scores = scorer.score(reference, generated_text)\n","        for key in all_rouge_scores:\n","            all_rouge_scores[key]['fmeasure'] += rouge_scores[key].fmeasure\n","            all_rouge_scores[key]['precision'] += rouge_scores[key].precision\n","            all_rouge_scores[key]['recall'] += rouge_scores[key].recall\n","\n","        all_bleu_scores += bleu.sentence_score(generated_text, [reference]).score\n","\n","        count += 1\n","\n","    avg_rouge_scores = {}\n","    for key in all_rouge_scores:\n","        avg_rouge_scores[key] = {metric: score / count for metric, score in all_rouge_scores[key].items()}\n","    avg_bleu_score = all_bleu_scores / count\n","\n","    return avg_rouge_scores, avg_bleu_score\n"],"metadata":{"id":"2d_1h3Yo0env","executionInfo":{"status":"ok","timestamp":1750733459496,"user_tz":-480,"elapsed":1,"user":{"displayName":"SU, XINGZE _","userId":"01580346516857497041"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["test_dataset_formatted = test_set.map(\n","    formatting_prompts_func,\n","    batched=True,\n","    remove_columns=test_set.column_names\n",")\n","test_rouge, test_bleu = evaluate_model(model, tokenizer, test_dataset_formatted)\n","print(\"Test Set Metrics:\")\n","print(\"ROUGE Scores:\", test_rouge)\n","print(\"BLEU Score:\", test_bleu)"],"metadata":{"id":"fGfkCdDJ0elZ","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["866c13239dd5450eb58870b851388397","ad3bdc7140df4c718b67b3a3d641979e","e484891336184a0f916486126402e9dc","f2e498f4a22c42c18b5a5e870d2dc7e0","9c3fc96af4d04d9aa9c4c420ba78b371","d3bcf436df314823adb31b00521eb0cf","7270ed2cac384614a8a3501979ad17e7","efcb625aa815449db8049a1309295cea","95a900b424694ab4b4af0992d539b430","1eeeefffe1c5458093e289c21e1b0f27","73cd8be4d43e4600b5a2f75ff7c6c3cc"]},"executionInfo":{"status":"ok","timestamp":1750733710513,"user_tz":-480,"elapsed":250154,"user":{"displayName":"SU, XINGZE _","userId":"01580346516857497041"}},"outputId":"f0afc7da-3962-437d-857f-9e5902ae0c33"},"execution_count":34,"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/120 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"866c13239dd5450eb58870b851388397"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n","WARNING:sacrebleu:It is recommended to enable `effective_order` for sentence-level BLEU.\n"]},{"output_type":"stream","name":"stdout","text":["Test Set Metrics:\n","ROUGE Scores: {'rouge1': {'fmeasure': 0.3946784969789285, 'precision': 0.4051854502524122, 'recall': 0.4033796877345059}, 'rouge2': {'fmeasure': 0.21179513131825636, 'precision': 0.21732846287112945, 'recall': 0.215895888797156}, 'rougeL': {'fmeasure': 0.3491536946535655, 'precision': 0.3581925984705251, 'recall': 0.3565503975435979}}\n","BLEU Score: 16.27422905874661\n"]}]},{"cell_type":"code","source":["torch.cuda.empty_cache()\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","model = AutoModelForCausalLM.from_pretrained(\n","    output_model_path,\n","    device_map=\"auto\" # Let transformers handle device placement\n",")\n","\n","tokenizer = AutoTokenizer.from_pretrained(output_model_path)\n","\n","# The model should already be on the device because of device_map=\"auto\"\n","# No need for an explicit model.to(device) call if device_map=\"auto\" is used\n","\n","def chat_with_model(model, tokenizer):\n","    print(\"Start chatting with the model. Type 'quit' to exit.\")\n","    while True:\n","        user_input = input(\"You: \")\n","        if user_input.lower() == 'quit':\n","            break\n","\n","        # Format the user input as a prompt\n","        prompt = f\"### Question:\\n{user_input}\\n\\n### Thought Process:\\n\"\n","\n","        # Ensure input_ids are on the correct device\n","        input_data = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True)\n","        input_ids = input_data.input_ids.to(model.device)\n","        attention_mask = input_data.attention_mask.to(model.device)\n","\n","        with torch.no_grad():\n","            outputs = model.generate(\n","                input_ids,\n","                max_new_tokens=200, # Adjust based on desired response length\n","                num_return_sequences=1,\n","                attention_mask=attention_mask,\n","                pad_token_id=tokenizer.eos_token_id,\n","                temperature=0.7, # Adjust for creativity (lower is less creative)\n","                top_p=0.9,       # Adjust for sampling\n","                do_sample=True   # Enable sampling\n","            )\n","\n","        generated_text = tokenizer.decode(outputs[0][len(input_ids[0]):], skip_special_tokens=True).strip()\n","\n","        # Find the start of the Answer section to only display the answer\n","        answer_start_index = generated_text.find(\"### Answer:\")\n","        if answer_start_index != -1:\n","            # Find the start of the next section (if any)\n","            next_section_index = generated_text.find(\"###\", answer_start_index + len(\"### Answer:\"))\n","            if next_section_index != -1:\n","                generated_answer = generated_text[answer_start_index + len(\"### Answer:\"):next_section_index].strip()\n","            else:\n","                generated_answer = generated_text[answer_start_index + len(\"### Answer:\"):].strip()\n","            print(f\"Model: {generated_answer}\")\n","        else:\n","            # If no explicit Answer section, print the generated text after the Thought Process\n","            thought_process_end_index = generated_text.find(\"\\n\\n### Answer:\")\n","            if thought_process_end_index != -1:\n","                print(f\"Model: {generated_text[:thought_process_end_index].strip()}\")\n","            else:\n","                 print(f\"Model: {generated_text.strip()}\")\n","\n","\n","# Start the chat interface\n","chat_with_model(model, tokenizer)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":136,"referenced_widgets":["43ed727277e741b982f632bccc16067a","31ebded91cc547998493fba3b39b6e73","3f5d88d3f5ca42549f47d2db1574cd37","5a34c9a7e1b94987b0f446f4261b09a3","b6699628520a48fc8b50082d72227eee","a8c5568463df477cadea5f04cd2b77a5","682f0bcf36b94ed8a3023c50a6f1d6bc","f51d0f7d31444416884514bfba530209","f261718d48344c8d937c7bb4cb8577b7","c279811e1ae8428c97f60314a51cc376","25e50ba5fe83485fb7709fd9c873e8a7"]},"id":"TmKItxMqzwrM","executionInfo":{"status":"ok","timestamp":1750683609099,"user_tz":-480,"elapsed":16798,"user":{"displayName":"SU, XINGZE _","userId":"01580346516857497041"}},"outputId":"25bcb9bc-f16a-42d8-feb8-6c3fdf8cfa73"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"43ed727277e741b982f632bccc16067a"}},"metadata":{}},{"name":"stdout","output_type":"stream","text":["Start chatting with the model. Type 'quit' to exit.\n","You: Please summarize <Sunrise on the Reaping>\n"]},{"output_type":"stream","name":"stderr","text":["Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"]},{"name":"stdout","output_type":"stream","text":["Model: The chapter begins with a 'clear morning', the Reaping crew 'hurried around' preparing, and the 'sun rises on the reaping'. Haymitch feels 'sick\n","You: quit\n"]}]},{"cell_type":"code","source":["# 1>\n","# What items does Haymitch give his mother and brother before leaving for the Games?\n","# 2>\n","# What is the name of the plant at Plutarch’s conservatory with a faint sweet rotten smell?\n","# 3>\n","# What item does Maysilee use to remove a spike from her cheek?\n","# 4>\n","# What is the item Maysilee knuckle-rolls on the train, and what is it made of?\n","# 5>\n","# What are the squirrel mutts’ primary movement method and coat color?"],"metadata":{"id":"Rg9I4jv3z0b0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def chat_with_model(model, tokenizer):\n","    print(\"Start chatting with the model. Type 'quit' to exit.\")\n","    while True:\n","        user_input = input(\"You: \")\n","        if user_input.lower() == 'quit':\n","            break\n","\n","        # Format the user input as a prompt\n","        prompt = f\"### Question:\\n{user_input}\\n\\n### Thought Process:\\n\"\n","\n","        # Ensure input_ids are on the correct device\n","        input_data = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True)\n","        input_ids = input_data.input_ids.to(model.device)\n","        attention_mask = input_data.attention_mask.to(model.device)\n","\n","        with torch.no_grad():\n","            outputs = model.generate(\n","                input_ids,\n","                max_new_tokens=200, # Adjust based on desired response length\n","                num_return_sequences=1,\n","                attention_mask=attention_mask,\n","                pad_token_id=tokenizer.eos_token_id,\n","                temperature=0.7, # Adjust for creativity (lower is less creative)\n","                top_p=0.9,       # Adjust for sampling\n","                do_sample=True   # Enable sampling\n","            )\n","\n","        generated_text = tokenizer.decode(outputs[0][len(input_ids[0]):], skip_special_tokens=True).strip()\n","\n","        # Find the start of the Answer section to only display the answer\n","        answer_start_index = generated_text.find(\"### Answer:\")\n","        if answer_start_index != -1:\n","            # Find the start of the next section (if any)\n","            next_section_index = generated_text.find(\"###\", answer_start_index + len(\"### Answer:\"))\n","            if next_section_index != -1:\n","                generated_answer = generated_text[answer_start_index + len(\"### Answer:\"):next_section_index].strip()\n","            else:\n","                generated_answer = generated_text[answer_start_index + len(\"### Answer:\"):].strip()\n","            print(f\"Model: {generated_answer}\")\n","        else:\n","            # If no explicit Answer section, print the generated text after the Thought Process\n","            thought_process_end_index = generated_text.find(\"\\n\\n### Answer:\")\n","            if thought_process_end_index != -1:\n","                print(f\"Model: {generated_text[:thought_process_end_index].strip()}\")\n","            else:\n","                 print(f\"Model: {generated_text.strip()}\")\n","\n","\n","# Start the chat interface\n","chat_with_model(model, tokenizer)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Afu4Jbwr-UFY","executionInfo":{"status":"ok","timestamp":1750687998406,"user_tz":-480,"elapsed":145692,"user":{"displayName":"SU, XINGZE _","userId":"01580346516857497041"}},"outputId":"18ba6c8a-e6a0-4da5-a613-be67df57e505"},"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Start chatting with the model. Type 'quit' to exit.\n","You: What items does Haymitch give his mother and brother before leaving for the Games?\n"]},{"output_type":"stream","name":"stderr","text":["Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"]},{"name":"stdout","output_type":"stream","text":["Model: Haymitch gives his mother 'a gold ring with a tiny carved figure of a swan on it' and his brother 'a pair of scissors, saying “I need them for the Peacekeepers. They’ll cut your tongue out for sure”'.\n","You: What is the name of the plant at Plutarch’s conservatory with a faint sweet rotten smell?\n","Model: The plant at Plutarch's conservatory with a 'faint sweet rotten smell' is called 'Daisys'.\n","You: What item does Maysilee use to remove a spike from her cheek?\n","Model: Maysilee uses her thumb to remove a spike from her cheek.\n","You: What is the item Maysilee knuckle-rolls on the train, and what is it made of?\n","Model: Maysilee knuckle-rolls on a 'piece of metal inlaid with a pattern of tiny stars and moons'.\n","You: What are the squirrel mutts’ primary movement method and coat color?\n","Model: The squirrel mutts primarily move by 'bouncing from branch to branch' and have 'gorgeous golden coats'.\n","You: quit\n"]}]},{"cell_type":"code","source":["import json\n","mcq_data_path = \"./reasoned_qa_output/qa_data.json\"\n","\n","# Load the MCQ data\n","with open(mcq_data_path, 'r') as f:\n","    mcq_data = json.load(f)\n","mcq_data"],"metadata":{"id":"OvvHi2VlIKh1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1750733730722,"user_tz":-480,"elapsed":37,"user":{"displayName":"SU, XINGZE _","userId":"01580346516857497041"}},"outputId":"a55d01d2-9e4f-446c-c883-ce03e018d746"},"execution_count":35,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[{'question': \"In the novel 'All Fours', what reason does the narrator's neighbor, Brian, give in a note for his concern?\",\n","  'options': {'A': 'He saw someone trying to break into her car.',\n","   'B': 'He witnessed a stranger using a telephoto lens to photograph her house.',\n","   'C': 'He found a suspicious package on her doorstep.',\n","   'D': 'He noticed a coyote lingering in her front yard.'},\n","  'answer': 'B'},\n"," {'question': \"According to Harris's theory in the book, what is the primary characteristic of a 'Parker'?\",\n","  'options': {'A': 'They enjoy long, uneventful drives and simple pleasures.',\n","   'B': 'They are cautious and always plan ahead.',\n","   'C': 'They need to perform impossible tasks and receive applause.',\n","   'D': 'They are introverted and prefer to stay home.'},\n","  'answer': 'C'},\n"," {'question': \"What is the narrator's stated motivation for deciding to drive across the country to New York?\",\n","  'options': {'A': \"To become a more grounded and 'chill' person, like a 'Driver'.\",\n","   'B': 'She has a deep-seated fear of flying.',\n","   'C': 'She needed to transport her car for an extended stay.',\n","   'D': 'To save money on airfare.'},\n","  'answer': 'A'},\n"," {'question': 'Where does the narrator first meet Davey?',\n","  'options': {'A': 'At the Excelsior motel where she is staying.',\n","   'B': \"At a restaurant in Monrovia called Fontana's.\",\n","   'C': 'At a gas station where he is cleaning her windshield.',\n","   'D': 'At the Hertz rental car lot where he works.'},\n","  'answer': 'C'},\n"," {'question': 'What does the narrator do with the $20,000 she received from a whiskey company?',\n","  'options': {'A': 'She uses it for her cross-country trip and a stay at the Carlyle Hotel.',\n","   'B': \"She hires Davey's wife, Claire, to completely redecorate her motel room.\",\n","   'C': 'She gives it to her friend Jordi as a grant for her art.',\n","   'D': 'She puts it into a savings account for her child, Sam.'},\n","  'answer': 'B'},\n"," {'question': 'What is the real reason the pop star Arkanda wanted to meet with the narrator?',\n","  'options': {'A': 'Arkanda wanted to collaborate on a secret music project.',\n","   'B': \"Arkanda was interested in optioning the narrator's book for a film.\",\n","   'C': 'They both experienced the same rare birth complication, Fetal-maternal Hemorrhage.',\n","   'D': \"Arkanda's assistant was a fan of the narrator's work.\"},\n","  'answer': 'C'},\n"," {'question': 'What does Davey reveal to be his secret artistic passion?',\n","  'options': {'A': 'He is a singer-songwriter.',\n","   'B': 'He is a street and hip-hop dancer.',\n","   'C': 'He carves bowls out of tree burls.',\n","   'D': 'He is a painter.'},\n","  'answer': 'B'},\n"," {'question': 'Who is Audra in relation to Davey?',\n","  'options': {'A': 'His aunt who owns the antique mall.',\n","   'B': 'His high school drama teacher.',\n","   'C': \"His mother's best friend who became his first sexual partner.\",\n","   'D': 'A talent agent who discovered his dancing.'},\n","  'answer': 'C'},\n"," {'question': 'What is the final agreement that the narrator and Harris come to about their marriage?',\n","  'options': {'A': 'They decide to get a divorce.',\n","   'B': 'They agree to remain married but are both free to see other people on designated nights.',\n","   'C': 'They commit to strict monogamy and couples therapy.',\n","   'D': 'They decide to live separately for a trial period.'},\n","  'answer': 'B'},\n"," {'question': \"What role does Harris play in order to have 'make-up sex' with the narrator after her trip?\",\n","  'options': {'A': 'Her neighbor Brian from the FBI.',\n","   'B': 'A fan of her work.',\n","   'C': 'A stranger they meet at a bar.',\n","   'D': 'The telephotographer who took pictures of her through her window.'},\n","  'answer': 'D'},\n"," {'question': 'Who is Kris, the person the narrator begins to date?',\n","  'options': {'A': 'A woman she meets at her new gym.',\n","   'B': \"Her manager Liza's ex-girlfriend.\",\n","   'C': 'The ex-girlfriend and muse of the famous artist Lore Estes.',\n","   'D': 'A therapist specializing in non-traditional relationships.'},\n","  'answer': 'C'},\n"," {'question': 'What event causes the final breakup between the narrator and Kris?',\n","  'options': {'A': 'Kris admits she is still in love with Lore Estes.',\n","   'B': 'Kris reveals she had sex with a wealthy art collector named Elsa.',\n","   'C': 'The narrator refuses to commit to a monogamous relationship.',\n","   'D': \"They have a major argument about the narrator's relationship with Harris.\"},\n","  'answer': 'B'},\n"," {'question': \"According to the narrator's father, why did his mother, Esther, commit suicide?\",\n","  'options': {'A': 'She was suffering from a terminal illness.',\n","   'B': \"She couldn't bear the thought of losing her physical beauty as she aged.\",\n","   'C': \"She was clinically depressed and in the 'deathfield'.\",\n","   'D': 'She had a large fight with her husband.'},\n","  'answer': 'B'},\n"," {'question': \"What object with 'CALL ME' painted on it does the narrator leave as a message for Davey?\",\n","  'options': {'A': 'A large rock.',\n","   'B': 'A canvas bag.',\n","   'C': 'A pink canvas folding chair.',\n","   'D': 'A piece of cardboard.'},\n","  'answer': 'C'},\n"," {'question': \"What surprising thing does the narrator learn about her mother's entry into menopause?\",\n","  'options': {'A': 'She never experienced any symptoms.',\n","   'B': 'A doctor removed her ovaries without her consent during a different surgery.',\n","   'C': 'She used hormone replacement therapy for over 20 years.',\n","   'D': 'She went through it at a very young age.'},\n","  'answer': 'B'},\n"," {'question': \"Who does the 'telephotographer' from the beginning of the novel turn out to be?\",\n","  'options': {'A': 'A private investigator hired by Harris.',\n","   'B': 'A stalker who is a fan of her work.',\n","   'C': 'Her neighbor, Brian, from the FBI.',\n","   'D': 'A real estate agent taking a photo for a marketing postcard.'},\n","  'answer': 'D'},\n"," {'question': 'What is the significance of the saluting gesture between the narrator and Harris?',\n","  'options': {'A': \"It's a secret signal to leave a party.\",\n","   'B': \"It's an inside joke about a movie they both love.\",\n","   'C': \"It's their long-standing gesture of recognition and steadfast devotion.\",\n","   'D': \"It's how they apologize after an argument.\"},\n","  'answer': 'C'},\n"," {'question': 'When the narrator experiences severe vertigo in her New York hotel, what does Jordi suggest is the cause?',\n","  'options': {'A': 'A panic attack brought on by stress.',\n","   'B': 'A tiny, displaced crystal in her inner ear.',\n","   'C': 'A side effect of her hormone replacement therapy.',\n","   'D': 'Food poisoning from the airline meal.'},\n","  'answer': 'B'},\n"," {'question': \"What is the name of Sam's beloved but neglectful wonder-nanny who later worked for Arkanda?\",\n","  'options': {'A': 'Leila', 'B': 'Tara', 'C': 'Jess', 'D': 'Caro'},\n","  'answer': 'C'},\n"," {'question': \"During the narrator's stay at the Excelsior, what intimate act does Davey perform for her in the bathroom?\",\n","  'options': {'A': 'He washes her hair.',\n","   'B': 'He gives her a foot massage.',\n","   'C': 'He changes her tampon.',\n","   'D': 'He draws a bath for her.'},\n","  'answer': 'C'},\n"," {'question': \"At the end of the novel, what does the narrator realize during Davey's dance performance in New York?\",\n","  'options': {'A': 'That he has stolen her dance moves.',\n","   'B': 'That she is still deeply in love with him.',\n","   'C': \"That the feeling of freedom from the motel room ('321') is everywhere and she can always access it.\",\n","   'D': 'That he has become more famous than she will ever be.'},\n","  'answer': 'C'},\n"," {'question': 'After her fight with Harris, what does the narrator learn about the shared history of all the women in her family?',\n","  'options': {'A': 'They all had affairs in their forties.',\n","   'B': 'They all suffered from severe depression.',\n","   'C': 'They all experienced Fetal-maternal Hemorrhage.',\n","   'D': \"Her grandmother and aunt both committed suicide after feeling they were 'too old'.\"},\n","  'answer': 'D'},\n"," {'question': \"What is the 'Third Thing,' according to Jordi's explanation of a Quaker concept?\",\n","  'options': {'A': 'A secret kept between two friends.',\n","   'B': 'The unspoken truth in a relationship.',\n","   'C': 'A neutral topic of conversation through which the soul can speak indirectly.',\n","   'D': 'An extramarital affair.'},\n","  'answer': 'C'},\n"," {'question': 'What item does the narrator buy back from Goodwill that she had previously donated?',\n","  'options': {'A': 'A pair of clogs.',\n","   'B': 'A cheap pink bathrobe.',\n","   'C': 'A collection of vintage records.',\n","   'D': 'A set of ceramic lions.'},\n","  'answer': 'B'},\n"," {'question': 'In the end, who completes the star-patterned tile floor in room 321?',\n","  'options': {'A': 'The narrator buys the missing tiles herself.',\n","   'B': 'Skip, the motel manager, finds matching tiles online.',\n","   'C': 'Davey and Claire return to install the final three tiles.',\n","   'D': 'Jordi creates custom tiles to complete the pattern.'},\n","  'answer': 'C'},\n"," {'question': \"What gift does Haymitch's girlfriend, Lenore Dove, give him for his sixteenth birthday?\",\n","  'options': {'A': 'A pocketknife',\n","   'B': 'A pint of white liquor',\n","   'C': 'A flint striker shaped like a snake and a bird',\n","   'D': 'A bag of multicolored gumdrops'},\n","  'answer': 'C'},\n"," {'question': 'How does Haymitch Abernathy become a tribute in the 50th Hunger Games?',\n","  'options': {'A': 'His name is drawn from the reaping ball.',\n","   'B': \"He volunteers to take his brother's place.\",\n","   'C': 'He is chosen as a replacement after intervening in a dispute to protect Lenore.',\n","   'D': 'He is punished for trying to escape the reaping.'},\n","  'answer': 'C'},\n"," {'question': 'What tragic event occurs during the chariot parade at the opening ceremonies?',\n","  'options': {'A': 'Haymitch falls out of the chariot and breaks his leg.',\n","   'B': 'Maysilee is attacked by another tribute.',\n","   'C': 'The chariot from District 6 crashes into the crowd.',\n","   'D': 'Louella McCoy is thrown from the chariot and dies.'},\n","  'answer': 'D'},\n"," {'question': 'Who are the two mentors assigned to the District 12 tributes?',\n","  'options': {'A': 'Effie Trinket and Caesar Flickerman',\n","   'B': 'Plutarch Heavensbee and Drusilla Sickle',\n","   'C': 'Mags from District 4 and Wiress from District 3',\n","   'D': 'Beetee from District 3 and a victor from District 1'},\n","  'answer': 'C'},\n"," {'question': 'What is the name the alliance of non-Career tributes gives themselves?',\n","  'options': {'A': 'The Rebels',\n","   'B': 'The Newcomers',\n","   'C': 'The Underdogs',\n","   'D': 'The Loose Cannons'},\n","  'answer': 'B'},\n"," {'question': 'How does Haymitch discover that the water and plants in the arena are poisonous?',\n","  'options': {'A': 'Maysilee warns him after she gets sick.',\n","   'B': 'He drinks from a stream and gets sick after seeing a rabbit die from it.',\n","   'C': 'A sponsor sends a note warning him.',\n","   'D': 'The Gamemakers make an announcement.'},\n","  'answer': 'B'},\n"," {'question': 'What is the primary weapon Maysilee Donner uses effectively in the arena?',\n","  'options': {'A': 'A bow and arrow',\n","   'B': 'A small knife',\n","   'C': 'A blowgun with poison darts',\n","   'D': 'A trident'},\n","  'answer': 'C'},\n"," {'question': 'What special feature does Haymitch discover at the edge of the arena beyond the woods?',\n","  'options': {'A': 'An electrified fence',\n","   'B': 'A deep chasm filled with water',\n","   'C': 'A force field that repels objects thrown at it',\n","   'D': 'A wall of fire'},\n","  'answer': 'C'},\n"," {'question': 'How is Silka, the female tribute from District 1, ultimately killed?',\n","  'options': {'A': 'Haymitch kills her with his ax.',\n","   'B': 'Maysilee shoots her with a poison dart.',\n","   'C': 'She is killed by a muttation.',\n","   'D': 'Her own ax rebounds off the force field and strikes her in the head.'},\n","  'answer': 'D'},\n"," {'question': \"What happens to Haymitch's family while he is in the Hunger Games?\",\n","  'options': {'A': \"They are moved to the Victor's Village.\",\n","   'B': 'They are taken to the Capitol for their safety.',\n","   'C': 'They are killed in a house fire set by the Capitol.',\n","   'D': 'They escape from District 12.'},\n","  'answer': 'C'},\n"," {'question': 'How does Lenore Dove die?',\n","  'options': {'A': 'She is executed by the Peacekeepers for her rebellious songs.',\n","   'B': 'She takes her own life out of grief.',\n","   'C': 'She is poisoned by gumdrops sent by President Snow.',\n","   'D': 'She dies of appendicitis.'},\n","  'answer': 'C'},\n"," {'question': 'What is the secret rebel plan that Beetee shares with Haymitch?',\n","  'options': {'A': 'To assassinate President Snow during the Victory Tour.',\n","   'B': \"To start a fire in the Gamemakers' control room.\",\n","   'C': 'To organize a mass escape of the tributes from the arena.',\n","   'D': \"To flood the arena's control center by blowing up a water tank.\"},\n","  'answer': 'D'},\n"," {'question': 'What nickname do the Newcomers decide to call the Career tributes?',\n","  'options': {'A': 'The Capitol Pets',\n","   'B': 'The Brutes',\n","   'C': 'The Near Beer Careers',\n","   'D': 'The Fakers'},\n","  'answer': 'C'},\n"," {'question': 'How does Maysilee Donner die in the arena?',\n","  'options': {'A': 'She is killed by Silka from District 1.',\n","   'B': 'She is attacked and killed by a flock of pink, bird-like mutts.',\n","   'C': 'She sacrifices herself to save Haymitch.',\n","   'D': 'She falls from a cliff.'},\n","  'answer': 'B'},\n"," {'question': 'What is the first thing President Snow says to Haymitch after he wins the Games?',\n","  'options': {'A': '“Congratulations on your victory.”',\n","   'B': '“You have made a powerful enemy today.”',\n","   'C': '“Enjoy your homecoming.”',\n","   'D': '“Snow lands on top.”'},\n","  'answer': 'C'},\n"," {'question': 'What is the overall design or shape of the 50th Hunger Games arena?',\n","  'options': {'A': 'A clock',\n","   'B': 'A giant eye',\n","   'C': 'A perfect circle',\n","   'D': 'A dense jungle with a central lake'},\n","  'answer': 'B'},\n"," {'question': 'Who provides the District 12 tributes with proper outfits for the interviews after their stylist, Magno Stift, fails to do so?',\n","  'options': {'A': 'Plutarch Heavensbee',\n","   'B': 'Mags',\n","   'C': 'Caesar Flickerman',\n","   'D': 'Effie Trinket'},\n","  'answer': 'D'},\n"," {'question': 'What does Haymitch do with the pitcher of milk he is supposed to give to a sick President Snow?',\n","  'options': {'A': 'He drops it on the floor.',\n","   'B': 'He gives it to Plutarch.',\n","   'C': 'He drinks it himself.',\n","   'D': 'He throws it at the President.'},\n","  'answer': 'C'},\n"," {'question': 'What does Haymitch realize about the beautiful landscape of the arena?',\n","  'options': {'A': 'It is an exact replica of the woods around District 12.',\n","   'B': 'The Gamemakers can change the weather at will.',\n","   'C': 'All the food and water outside the Cornucopia are poisonous.',\n","   'D': 'It is filled with hidden traps and cameras.'},\n","  'answer': 'C'},\n"," {'question': \"What does Plutarch Heavensbee tell Haymitch about the arena's sun?\",\n","  'options': {'A': 'It is much hotter than a normal sun.',\n","   'B': 'It is an illusion created by the Gamemakers.',\n","   'C': 'It is in sync with the real sun, allowing him to tell direction.',\n","   'D': 'It can be turned off at night.'},\n","  'answer': 'C'},\n"," {'question': 'What does Haymitch throw at the force field in his final move against Silka?',\n","  'options': {'A': 'His knife', 'B': 'His ax', 'C': 'A rock', 'D': 'A spear'},\n","  'answer': 'B'},\n"," {'question': \"After the Games, what does Haymitch see on a wall in a back alley that confirms Lenore Dove's rebellious activities?\",\n","  'options': {'A': 'A drawing of a mockingjay',\n","   'B': 'A song lyric she wrote',\n","   'C': 'A rebel slogan sprayed in bright orange paint',\n","   'D': 'Her signature'},\n","  'answer': 'C'},\n"," {'question': \"What does Maysilee use to create a makeshift glue to repair Kerna's broken sunflower token?\",\n","  'options': {'A': 'Tree sap and water',\n","   'B': 'Flour, water, and salt',\n","   'C': 'Crushed berries and ash',\n","   'D': 'Melted paraffin'},\n","  'answer': 'B'},\n"," {'question': 'What is the first muttation Haymitch successfully fights off using his flint striker and a gas plant?',\n","  'options': {'A': 'Carnivorous squirrels',\n","   'B': 'A flock of pink birds',\n","   'C': 'A swarm of stinging butterflies',\n","   'D': 'A giant porcupine'},\n","  'answer': 'C'},\n"," {'question': \"What is the final 'poster' Haymitch creates in the arena?\",\n","  'options': {'A': 'Killing Silka with her own ax.',\n","   'B': \"Leaving Maysilee's body for the Capitol to see.\",\n","   'C': \"Carrying Louella's body to President Snow.\",\n","   'D': 'Throwing the explosive sunflower at the force field.'},\n","  'answer': 'D'}]"]},"metadata":{},"execution_count":35}]},{"cell_type":"code","source":["def evaluate_mcq(model, tokenizer, mcq_data):\n","    model.eval()\n","    correct_count = 0\n","    total_count = 0\n","\n","    for item in mcq_data:\n","        question = item[\"question\"]\n","        options = \"\\n\".join([f\"{key}. {value}\" for key, value in item[\"options\"].items()])\n","        correct_answer_key = item[\"answer\"]\n","\n","        prompt = f\"### Question:\\n{question}\\n{options}\\n\\n### Thought Process:\\n\"\n","\n","        input_data = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True)\n","        input_ids = input_data.input_ids.to(model.device)\n","        attention_mask = input_data.attention_mask.to(model.device)\n","\n","        with torch.no_grad():\n","            outputs = model.generate(\n","                input_ids,\n","                max_new_tokens=200,\n","                num_return_sequences=1,\n","                pad_token_id=tokenizer.eos_token_id,\n","                attention_mask=attention_mask,\n","                temperature=0.1, # Keep temperature low for deterministic answers,\n","                do_sample=False  # Disable sampling for deterministic answers\n","            )\n","\n","        generated_text = tokenizer.decode(outputs[0][len(input_ids[0]):], skip_special_tokens=True).strip()\n","\n","        # Extract the predicted answer key from the generated text\n","        # This part might need adjustment based on the exact output format of your model\n","        # Look for the part after \"### Answer:\" and try to match it to the option keys (A, B, C, D)\n","        predicted_answer_key = None\n","        answer_start_index = generated_text.find(\"### Answer:\")\n","        if answer_start_index != -1:\n","            answer_content = generated_text[answer_start_index + len(\"### Answer:\"):].strip()\n","            # Simple heuristic: look for a single character (like A, B, C, D) at the start\n","            if len(answer_content) > 0 and answer_content[0] in item[\"options\"].keys():\n","                predicted_answer_key = answer_content[0]\n","            elif len(answer_content) > 1 and answer_content[1] == '.' and answer_content[0] in item[\"options\"].keys():\n","                 predicted_answer_key = answer_content[0]\n","\n","\n","        print(f\"Question: {question}\")\n","        print(f\"Predicted Answer Key: {predicted_answer_key}\")\n","        print(f\"Correct Answer Key: {correct_answer_key}\")\n","\n","\n","        if predicted_answer_key is not None and predicted_answer_key == correct_answer_key:\n","            correct_count += 1\n","            print(\"Result: Correct\")\n","        else:\n","            print(\"Result: Incorrect\")\n","\n","        total_count += 1\n","        print(\"-\" * 20)\n","\n","\n","    accuracy = (correct_count / total_count) * 100 if total_count > 0 else 0\n","    return accuracy\n","\n","print(\"\\nEvaluating on MCQ data...\")\n","mcq_accuracy = evaluate_mcq(model, tokenizer, mcq_data)\n","print(f\"\\nMCQ Accuracy: {mcq_accuracy:.2f}%\")\n","\n","torch.cuda.empty_cache()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kbpgCs3gsKVX","executionInfo":{"status":"ok","timestamp":1750733929846,"user_tz":-480,"elapsed":198057,"user":{"displayName":"SU, XINGZE _","userId":"01580346516857497041"}},"outputId":"bc446932-60c1-478e-e33b-cbd9ddbe47c3"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stderr","text":["The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"]},{"output_type":"stream","name":"stdout","text":["\n","Evaluating on MCQ data...\n"]},{"output_type":"stream","name":"stderr","text":["The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"]},{"output_type":"stream","name":"stdout","text":["Question: In the novel 'All Fours', what reason does the narrator's neighbor, Brian, give in a note for his concern?\n","Predicted Answer Key: B\n","Correct Answer Key: B\n","Result: Correct\n","--------------------\n"]},{"output_type":"stream","name":"stderr","text":["The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"]},{"output_type":"stream","name":"stdout","text":["Question: According to Harris's theory in the book, what is the primary characteristic of a 'Parker'?\n","Predicted Answer Key: A\n","Correct Answer Key: C\n","Result: Incorrect\n","--------------------\n"]},{"output_type":"stream","name":"stderr","text":["The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"]},{"output_type":"stream","name":"stdout","text":["Question: What is the narrator's stated motivation for deciding to drive across the country to New York?\n","Predicted Answer Key: None\n","Correct Answer Key: A\n","Result: Incorrect\n","--------------------\n"]},{"output_type":"stream","name":"stderr","text":["The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"]},{"output_type":"stream","name":"stdout","text":["Question: Where does the narrator first meet Davey?\n","Predicted Answer Key: None\n","Correct Answer Key: C\n","Result: Incorrect\n","--------------------\n"]},{"output_type":"stream","name":"stderr","text":["The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"]},{"output_type":"stream","name":"stdout","text":["Question: What does the narrator do with the $20,000 she received from a whiskey company?\n","Predicted Answer Key: None\n","Correct Answer Key: B\n","Result: Incorrect\n","--------------------\n"]},{"output_type":"stream","name":"stderr","text":["The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"]},{"output_type":"stream","name":"stdout","text":["Question: What is the real reason the pop star Arkanda wanted to meet with the narrator?\n","Predicted Answer Key: A\n","Correct Answer Key: C\n","Result: Incorrect\n","--------------------\n"]},{"output_type":"stream","name":"stderr","text":["The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"]},{"output_type":"stream","name":"stdout","text":["Question: What does Davey reveal to be his secret artistic passion?\n","Predicted Answer Key: D\n","Correct Answer Key: B\n","Result: Incorrect\n","--------------------\n"]},{"output_type":"stream","name":"stderr","text":["The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"]},{"output_type":"stream","name":"stdout","text":["Question: Who is Audra in relation to Davey?\n","Predicted Answer Key: A\n","Correct Answer Key: C\n","Result: Incorrect\n","--------------------\n"]},{"output_type":"stream","name":"stderr","text":["The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"]},{"output_type":"stream","name":"stdout","text":["Question: What is the final agreement that the narrator and Harris come to about their marriage?\n","Predicted Answer Key: None\n","Correct Answer Key: B\n","Result: Incorrect\n","--------------------\n"]},{"output_type":"stream","name":"stderr","text":["The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"]},{"output_type":"stream","name":"stdout","text":["Question: What role does Harris play in order to have 'make-up sex' with the narrator after her trip?\n","Predicted Answer Key: None\n","Correct Answer Key: D\n","Result: Incorrect\n","--------------------\n"]},{"output_type":"stream","name":"stderr","text":["The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"]},{"output_type":"stream","name":"stdout","text":["Question: Who is Kris, the person the narrator begins to date?\n","Predicted Answer Key: None\n","Correct Answer Key: C\n","Result: Incorrect\n","--------------------\n"]},{"output_type":"stream","name":"stderr","text":["The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"]},{"output_type":"stream","name":"stdout","text":["Question: What event causes the final breakup between the narrator and Kris?\n","Predicted Answer Key: None\n","Correct Answer Key: B\n","Result: Incorrect\n","--------------------\n"]},{"output_type":"stream","name":"stderr","text":["The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"]},{"output_type":"stream","name":"stdout","text":["Question: According to the narrator's father, why did his mother, Esther, commit suicide?\n","Predicted Answer Key: A\n","Correct Answer Key: B\n","Result: Incorrect\n","--------------------\n"]},{"output_type":"stream","name":"stderr","text":["The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"]},{"output_type":"stream","name":"stdout","text":["Question: What object with 'CALL ME' painted on it does the narrator leave as a message for Davey?\n","Predicted Answer Key: None\n","Correct Answer Key: C\n","Result: Incorrect\n","--------------------\n"]},{"output_type":"stream","name":"stderr","text":["The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"]},{"output_type":"stream","name":"stdout","text":["Question: What surprising thing does the narrator learn about her mother's entry into menopause?\n","Predicted Answer Key: None\n","Correct Answer Key: B\n","Result: Incorrect\n","--------------------\n"]},{"output_type":"stream","name":"stderr","text":["The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"]},{"output_type":"stream","name":"stdout","text":["Question: Who does the 'telephotographer' from the beginning of the novel turn out to be?\n","Predicted Answer Key: None\n","Correct Answer Key: D\n","Result: Incorrect\n","--------------------\n"]},{"output_type":"stream","name":"stderr","text":["The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"]},{"output_type":"stream","name":"stdout","text":["Question: What is the significance of the saluting gesture between the narrator and Harris?\n","Predicted Answer Key: None\n","Correct Answer Key: C\n","Result: Incorrect\n","--------------------\n"]},{"output_type":"stream","name":"stderr","text":["The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"]},{"output_type":"stream","name":"stdout","text":["Question: When the narrator experiences severe vertigo in her New York hotel, what does Jordi suggest is the cause?\n","Predicted Answer Key: None\n","Correct Answer Key: B\n","Result: Incorrect\n","--------------------\n"]},{"output_type":"stream","name":"stderr","text":["The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"]},{"output_type":"stream","name":"stdout","text":["Question: What is the name of Sam's beloved but neglectful wonder-nanny who later worked for Arkanda?\n","Predicted Answer Key: None\n","Correct Answer Key: C\n","Result: Incorrect\n","--------------------\n"]},{"output_type":"stream","name":"stderr","text":["The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"]},{"output_type":"stream","name":"stdout","text":["Question: During the narrator's stay at the Excelsior, what intimate act does Davey perform for her in the bathroom?\n","Predicted Answer Key: D\n","Correct Answer Key: C\n","Result: Incorrect\n","--------------------\n"]},{"output_type":"stream","name":"stderr","text":["The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"]},{"output_type":"stream","name":"stdout","text":["Question: At the end of the novel, what does the narrator realize during Davey's dance performance in New York?\n","Predicted Answer Key: None\n","Correct Answer Key: C\n","Result: Incorrect\n","--------------------\n"]},{"output_type":"stream","name":"stderr","text":["The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"]},{"output_type":"stream","name":"stdout","text":["Question: After her fight with Harris, what does the narrator learn about the shared history of all the women in her family?\n","Predicted Answer Key: None\n","Correct Answer Key: D\n","Result: Incorrect\n","--------------------\n"]},{"output_type":"stream","name":"stderr","text":["The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"]},{"output_type":"stream","name":"stdout","text":["Question: What is the 'Third Thing,' according to Jordi's explanation of a Quaker concept?\n","Predicted Answer Key: A\n","Correct Answer Key: C\n","Result: Incorrect\n","--------------------\n"]},{"output_type":"stream","name":"stderr","text":["The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"]},{"output_type":"stream","name":"stdout","text":["Question: What item does the narrator buy back from Goodwill that she had previously donated?\n","Predicted Answer Key: None\n","Correct Answer Key: B\n","Result: Incorrect\n","--------------------\n"]},{"output_type":"stream","name":"stderr","text":["The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"]},{"output_type":"stream","name":"stdout","text":["Question: In the end, who completes the star-patterned tile floor in room 321?\n","Predicted Answer Key: None\n","Correct Answer Key: C\n","Result: Incorrect\n","--------------------\n"]},{"output_type":"stream","name":"stderr","text":["The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"]},{"output_type":"stream","name":"stdout","text":["Question: What gift does Haymitch's girlfriend, Lenore Dove, give him for his sixteenth birthday?\n","Predicted Answer Key: None\n","Correct Answer Key: C\n","Result: Incorrect\n","--------------------\n"]},{"output_type":"stream","name":"stderr","text":["The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"]},{"output_type":"stream","name":"stdout","text":["Question: How does Haymitch Abernathy become a tribute in the 50th Hunger Games?\n","Predicted Answer Key: None\n","Correct Answer Key: C\n","Result: Incorrect\n","--------------------\n"]},{"output_type":"stream","name":"stderr","text":["The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"]},{"output_type":"stream","name":"stdout","text":["Question: What tragic event occurs during the chariot parade at the opening ceremonies?\n","Predicted Answer Key: D\n","Correct Answer Key: D\n","Result: Correct\n","--------------------\n"]},{"output_type":"stream","name":"stderr","text":["The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"]},{"output_type":"stream","name":"stdout","text":["Question: Who are the two mentors assigned to the District 12 tributes?\n","Predicted Answer Key: None\n","Correct Answer Key: C\n","Result: Incorrect\n","--------------------\n"]},{"output_type":"stream","name":"stderr","text":["The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"]},{"output_type":"stream","name":"stdout","text":["Question: What is the name the alliance of non-Career tributes gives themselves?\n","Predicted Answer Key: None\n","Correct Answer Key: B\n","Result: Incorrect\n","--------------------\n"]},{"output_type":"stream","name":"stderr","text":["The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"]},{"output_type":"stream","name":"stdout","text":["Question: How does Haymitch discover that the water and plants in the arena are poisonous?\n","Predicted Answer Key: None\n","Correct Answer Key: B\n","Result: Incorrect\n","--------------------\n"]},{"output_type":"stream","name":"stderr","text":["The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"]},{"output_type":"stream","name":"stdout","text":["Question: What is the primary weapon Maysilee Donner uses effectively in the arena?\n","Predicted Answer Key: None\n","Correct Answer Key: C\n","Result: Incorrect\n","--------------------\n"]},{"output_type":"stream","name":"stderr","text":["The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"]},{"output_type":"stream","name":"stdout","text":["Question: What special feature does Haymitch discover at the edge of the arena beyond the woods?\n","Predicted Answer Key: None\n","Correct Answer Key: C\n","Result: Incorrect\n","--------------------\n"]},{"output_type":"stream","name":"stderr","text":["The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"]},{"output_type":"stream","name":"stdout","text":["Question: How is Silka, the female tribute from District 1, ultimately killed?\n","Predicted Answer Key: None\n","Correct Answer Key: D\n","Result: Incorrect\n","--------------------\n"]},{"output_type":"stream","name":"stderr","text":["The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"]},{"output_type":"stream","name":"stdout","text":["Question: What happens to Haymitch's family while he is in the Hunger Games?\n","Predicted Answer Key: None\n","Correct Answer Key: C\n","Result: Incorrect\n","--------------------\n"]},{"output_type":"stream","name":"stderr","text":["The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"]},{"output_type":"stream","name":"stdout","text":["Question: How does Lenore Dove die?\n","Predicted Answer Key: None\n","Correct Answer Key: C\n","Result: Incorrect\n","--------------------\n"]},{"output_type":"stream","name":"stderr","text":["The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"]},{"output_type":"stream","name":"stdout","text":["Question: What is the secret rebel plan that Beetee shares with Haymitch?\n","Predicted Answer Key: B\n","Correct Answer Key: D\n","Result: Incorrect\n","--------------------\n"]},{"output_type":"stream","name":"stderr","text":["The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"]},{"output_type":"stream","name":"stdout","text":["Question: What nickname do the Newcomers decide to call the Career tributes?\n","Predicted Answer Key: None\n","Correct Answer Key: C\n","Result: Incorrect\n","--------------------\n"]},{"output_type":"stream","name":"stderr","text":["The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"]},{"output_type":"stream","name":"stdout","text":["Question: How does Maysilee Donner die in the arena?\n","Predicted Answer Key: None\n","Correct Answer Key: B\n","Result: Incorrect\n","--------------------\n"]},{"output_type":"stream","name":"stderr","text":["The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"]},{"output_type":"stream","name":"stdout","text":["Question: What is the first thing President Snow says to Haymitch after he wins the Games?\n","Predicted Answer Key: None\n","Correct Answer Key: C\n","Result: Incorrect\n","--------------------\n"]},{"output_type":"stream","name":"stderr","text":["The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"]},{"output_type":"stream","name":"stdout","text":["Question: What is the overall design or shape of the 50th Hunger Games arena?\n","Predicted Answer Key: None\n","Correct Answer Key: B\n","Result: Incorrect\n","--------------------\n"]},{"output_type":"stream","name":"stderr","text":["The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"]},{"output_type":"stream","name":"stdout","text":["Question: Who provides the District 12 tributes with proper outfits for the interviews after their stylist, Magno Stift, fails to do so?\n","Predicted Answer Key: None\n","Correct Answer Key: D\n","Result: Incorrect\n","--------------------\n"]},{"output_type":"stream","name":"stderr","text":["The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"]},{"output_type":"stream","name":"stdout","text":["Question: What does Haymitch do with the pitcher of milk he is supposed to give to a sick President Snow?\n","Predicted Answer Key: None\n","Correct Answer Key: C\n","Result: Incorrect\n","--------------------\n"]},{"output_type":"stream","name":"stderr","text":["The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"]},{"output_type":"stream","name":"stdout","text":["Question: What does Haymitch realize about the beautiful landscape of the arena?\n","Predicted Answer Key: None\n","Correct Answer Key: C\n","Result: Incorrect\n","--------------------\n"]},{"output_type":"stream","name":"stderr","text":["The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"]},{"output_type":"stream","name":"stdout","text":["Question: What does Plutarch Heavensbee tell Haymitch about the arena's sun?\n","Predicted Answer Key: None\n","Correct Answer Key: C\n","Result: Incorrect\n","--------------------\n"]},{"output_type":"stream","name":"stderr","text":["The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"]},{"output_type":"stream","name":"stdout","text":["Question: What does Haymitch throw at the force field in his final move against Silka?\n","Predicted Answer Key: None\n","Correct Answer Key: B\n","Result: Incorrect\n","--------------------\n"]},{"output_type":"stream","name":"stderr","text":["The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"]},{"output_type":"stream","name":"stdout","text":["Question: After the Games, what does Haymitch see on a wall in a back alley that confirms Lenore Dove's rebellious activities?\n","Predicted Answer Key: None\n","Correct Answer Key: C\n","Result: Incorrect\n","--------------------\n"]},{"output_type":"stream","name":"stderr","text":["The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"]},{"output_type":"stream","name":"stdout","text":["Question: What does Maysilee use to create a makeshift glue to repair Kerna's broken sunflower token?\n","Predicted Answer Key: None\n","Correct Answer Key: B\n","Result: Incorrect\n","--------------------\n"]},{"output_type":"stream","name":"stderr","text":["The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"]},{"output_type":"stream","name":"stdout","text":["Question: What is the first muttation Haymitch successfully fights off using his flint striker and a gas plant?\n","Predicted Answer Key: None\n","Correct Answer Key: C\n","Result: Incorrect\n","--------------------\n","Question: What is the final 'poster' Haymitch creates in the arena?\n","Predicted Answer Key: None\n","Correct Answer Key: D\n","Result: Incorrect\n","--------------------\n","\n","MCQ Accuracy: 4.00%\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"JB9J1cgosMW1"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","machine_shape":"hm","provenance":[],"authorship_tag":"ABX9TyMGT98LNyb6ozclCN0s4qGR"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"43ed727277e741b982f632bccc16067a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_31ebded91cc547998493fba3b39b6e73","IPY_MODEL_3f5d88d3f5ca42549f47d2db1574cd37","IPY_MODEL_5a34c9a7e1b94987b0f446f4261b09a3"],"layout":"IPY_MODEL_b6699628520a48fc8b50082d72227eee"}},"31ebded91cc547998493fba3b39b6e73":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a8c5568463df477cadea5f04cd2b77a5","placeholder":"​","style":"IPY_MODEL_682f0bcf36b94ed8a3023c50a6f1d6bc","value":"Loading checkpoint shards: 100%"}},"3f5d88d3f5ca42549f47d2db1574cd37":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f51d0f7d31444416884514bfba530209","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f261718d48344c8d937c7bb4cb8577b7","value":2}},"5a34c9a7e1b94987b0f446f4261b09a3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c279811e1ae8428c97f60314a51cc376","placeholder":"​","style":"IPY_MODEL_25e50ba5fe83485fb7709fd9c873e8a7","value":" 2/2 [00:01&lt;00:00,  1.42s/it]"}},"b6699628520a48fc8b50082d72227eee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a8c5568463df477cadea5f04cd2b77a5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"682f0bcf36b94ed8a3023c50a6f1d6bc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f51d0f7d31444416884514bfba530209":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f261718d48344c8d937c7bb4cb8577b7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c279811e1ae8428c97f60314a51cc376":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"25e50ba5fe83485fb7709fd9c873e8a7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"40a10b89b1794ea6b585a6f2743a344f":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":[],"layout":"IPY_MODEL_dc0dc9c99b44403f9f56fb52d49cb373"}},"40f1a1d3d7664facafa6edcba82a652f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b9347bfa4fca4a32acea784759f1e930","placeholder":"​","style":"IPY_MODEL_23f1942b0dd448d6b6009b9b21b3e9be","value":"<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"}},"1b7b16de18b24fda8951663e873eb312":{"model_module":"@jupyter-widgets/controls","model_name":"PasswordModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"PasswordModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"PasswordView","continuous_update":true,"description":"Token:","description_tooltip":null,"disabled":false,"layout":"IPY_MODEL_379b28d65f824727a695df2137e21801","placeholder":"​","style":"IPY_MODEL_4a5ac4f55d8c4e5e9aa6da179cbe60fb","value":""}},"907b534bcefe45d8952ba2f84c78a7c7":{"model_module":"@jupyter-widgets/controls","model_name":"CheckboxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"CheckboxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"CheckboxView","description":"Add token as git credential?","description_tooltip":null,"disabled":false,"indent":true,"layout":"IPY_MODEL_7ff8750ed05d437382b4a6d6180071ab","style":"IPY_MODEL_eed2b53a8b3d48ac888686a507ee5d2f","value":true}},"9a11e431da34472494c3e4bad546308e":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ButtonView","button_style":"","description":"Login","disabled":false,"icon":"","layout":"IPY_MODEL_9f1a80105653403fbb2fc6349a0064b7","style":"IPY_MODEL_fb83214543e847ae9172bfdb5f1dff12","tooltip":""}},"06c23b83814244848e4b6c1409782b6f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_eee5c07f2b5742d7ae87193433b15019","placeholder":"​","style":"IPY_MODEL_25dbd57656ca4f4c813a794b7eb51ded","value":"\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"}},"dc0dc9c99b44403f9f56fb52d49cb373":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":"center","align_self":null,"border":null,"bottom":null,"display":"flex","flex":null,"flex_flow":"column","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"50%"}},"b9347bfa4fca4a32acea784759f1e930":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"23f1942b0dd448d6b6009b9b21b3e9be":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"379b28d65f824727a695df2137e21801":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4a5ac4f55d8c4e5e9aa6da179cbe60fb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7ff8750ed05d437382b4a6d6180071ab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eed2b53a8b3d48ac888686a507ee5d2f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9f1a80105653403fbb2fc6349a0064b7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fb83214543e847ae9172bfdb5f1dff12":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","button_color":null,"font_weight":""}},"eee5c07f2b5742d7ae87193433b15019":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"25dbd57656ca4f4c813a794b7eb51ded":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"89ec70f68da84cd9a32bfdd0c841ede2":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6870858d4f6b442bb147f44a3d4887c5","placeholder":"​","style":"IPY_MODEL_c69e16ce52e64a0bb64af9c68cb39eea","value":"Connecting..."}},"6870858d4f6b442bb147f44a3d4887c5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c69e16ce52e64a0bb64af9c68cb39eea":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1b22405c0ed642c48ab8a3a3c4ecc25d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5319008cf0434ec48604dd5d584be862","IPY_MODEL_cfe9fe52d23c4e2c83c45230a7d4e836","IPY_MODEL_74b8a752d37b4810a4355e1d2ed338a6"],"layout":"IPY_MODEL_18910dbdd6fe41c2b8605e646bc6666a"}},"5319008cf0434ec48604dd5d584be862":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_005f8dddb7644f548cac2855464a2172","placeholder":"​","style":"IPY_MODEL_8ae148f64ca84e12afa7a15e1d6630cc","value":"Loading checkpoint shards: 100%"}},"cfe9fe52d23c4e2c83c45230a7d4e836":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0c3993f819f245e39fd21ddf325025b7","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_94cd60e792e4468598082e68c3f17915","value":2}},"74b8a752d37b4810a4355e1d2ed338a6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_329681ec6a314d7ea8daa8e932907c5c","placeholder":"​","style":"IPY_MODEL_831f5c63227a425b8208f64c6e3ca6f4","value":" 2/2 [00:01&lt;00:00,  1.65s/it]"}},"18910dbdd6fe41c2b8605e646bc6666a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"005f8dddb7644f548cac2855464a2172":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8ae148f64ca84e12afa7a15e1d6630cc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0c3993f819f245e39fd21ddf325025b7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"94cd60e792e4468598082e68c3f17915":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"329681ec6a314d7ea8daa8e932907c5c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"831f5c63227a425b8208f64c6e3ca6f4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4658ebe753924c0d8c6740f6f14c7bde":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2223be318d004b5a9edb413536708fe2","IPY_MODEL_561aea7909444dd7bc27afc5576fea9f","IPY_MODEL_00321108acbf49208725b47ccbb9a7ea"],"layout":"IPY_MODEL_f0a464ee653047ed930706e0ef27981d"}},"2223be318d004b5a9edb413536708fe2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9bb49c37888742b483fc323bbf7ea4a3","placeholder":"​","style":"IPY_MODEL_e78f3450efdc4a73adadbf17de8c651e","value":"Map: 100%"}},"561aea7909444dd7bc27afc5576fea9f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c2b7d5d466444c46bcd3b77199ce508c","max":958,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3b72e13b13264b7a8b757426fa121c71","value":958}},"00321108acbf49208725b47ccbb9a7ea":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b0f9c9b50988461b859375826ef58afb","placeholder":"​","style":"IPY_MODEL_465589a9b37f4f6f9ba0e52ec87c8599","value":" 958/958 [00:00&lt;00:00, 28495.25 examples/s]"}},"f0a464ee653047ed930706e0ef27981d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9bb49c37888742b483fc323bbf7ea4a3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e78f3450efdc4a73adadbf17de8c651e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c2b7d5d466444c46bcd3b77199ce508c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3b72e13b13264b7a8b757426fa121c71":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b0f9c9b50988461b859375826ef58afb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"465589a9b37f4f6f9ba0e52ec87c8599":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"336385f0ff8e447f95f84b4b624dbacd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_84eeec6527a04792b674b7b169b37440","IPY_MODEL_870a5992873d471d96f755cf11cd1414","IPY_MODEL_7ffefcb7eccc41b39007527ff8ac8b6b"],"layout":"IPY_MODEL_04058eaf525d49a282ead7e8635fb4f6"}},"84eeec6527a04792b674b7b169b37440":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_833d08681e484594b030069ccc18129f","placeholder":"​","style":"IPY_MODEL_974fdaf5365a4334bc34773449d9dca6","value":"Map: 100%"}},"870a5992873d471d96f755cf11cd1414":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3e255235e7dd4c9e8d96b4e4c75d08f0","max":120,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b21fd5f618dc407e8a235ec40151ea84","value":120}},"7ffefcb7eccc41b39007527ff8ac8b6b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e0e8defadfce4d1ea24c7ee5c66bad54","placeholder":"​","style":"IPY_MODEL_8af4b0b432bd4cf2a834579391750f9d","value":" 120/120 [00:00&lt;00:00, 7567.64 examples/s]"}},"04058eaf525d49a282ead7e8635fb4f6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"833d08681e484594b030069ccc18129f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"974fdaf5365a4334bc34773449d9dca6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3e255235e7dd4c9e8d96b4e4c75d08f0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b21fd5f618dc407e8a235ec40151ea84":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e0e8defadfce4d1ea24c7ee5c66bad54":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8af4b0b432bd4cf2a834579391750f9d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c5a5a1dd7690428482adbe67e8f929aa":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_33c39b3124044418be14d7d254e87118","IPY_MODEL_8351e92ce22541c8b8357352fa17d99c","IPY_MODEL_06b1e19032bc4f0f9a8f03b02c14aee9"],"layout":"IPY_MODEL_0af55f1965934ad28e6d19f18a2e11eb"}},"33c39b3124044418be14d7d254e87118":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_82af2515349044f4958546e78ab382e4","placeholder":"​","style":"IPY_MODEL_38b2508ccf6d49478eee55d29710bbd4","value":"Loading checkpoint shards: 100%"}},"8351e92ce22541c8b8357352fa17d99c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a666052503154da2920fcca8a753b7b5","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d8f3cd0b68eb41bd8012c03de44669b4","value":2}},"06b1e19032bc4f0f9a8f03b02c14aee9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_76cf3c26dd564f68854821ab78fb2fec","placeholder":"​","style":"IPY_MODEL_0debd9e0e90b48bcbd84a6eec94e176a","value":" 2/2 [00:01&lt;00:00,  1.55s/it]"}},"0af55f1965934ad28e6d19f18a2e11eb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"82af2515349044f4958546e78ab382e4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"38b2508ccf6d49478eee55d29710bbd4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a666052503154da2920fcca8a753b7b5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d8f3cd0b68eb41bd8012c03de44669b4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"76cf3c26dd564f68854821ab78fb2fec":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0debd9e0e90b48bcbd84a6eec94e176a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"866c13239dd5450eb58870b851388397":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ad3bdc7140df4c718b67b3a3d641979e","IPY_MODEL_e484891336184a0f916486126402e9dc","IPY_MODEL_f2e498f4a22c42c18b5a5e870d2dc7e0"],"layout":"IPY_MODEL_9c3fc96af4d04d9aa9c4c420ba78b371"}},"ad3bdc7140df4c718b67b3a3d641979e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d3bcf436df314823adb31b00521eb0cf","placeholder":"​","style":"IPY_MODEL_7270ed2cac384614a8a3501979ad17e7","value":"Map: 100%"}},"e484891336184a0f916486126402e9dc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_efcb625aa815449db8049a1309295cea","max":120,"min":0,"orientation":"horizontal","style":"IPY_MODEL_95a900b424694ab4b4af0992d539b430","value":120}},"f2e498f4a22c42c18b5a5e870d2dc7e0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1eeeefffe1c5458093e289c21e1b0f27","placeholder":"​","style":"IPY_MODEL_73cd8be4d43e4600b5a2f75ff7c6c3cc","value":" 120/120 [00:00&lt;00:00, 8002.49 examples/s]"}},"9c3fc96af4d04d9aa9c4c420ba78b371":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d3bcf436df314823adb31b00521eb0cf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7270ed2cac384614a8a3501979ad17e7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"efcb625aa815449db8049a1309295cea":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"95a900b424694ab4b4af0992d539b430":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1eeeefffe1c5458093e289c21e1b0f27":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"73cd8be4d43e4600b5a2f75ff7c6c3cc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}